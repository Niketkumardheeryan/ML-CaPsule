{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"2d19769d3d823d95e24e3e5a549030117159de4f"},"source":["# Long Short Term Memory from Scratch\n"]},{"cell_type":"markdown","metadata":{"_uuid":"53caf20b4edf5889ebdd350cefb9c6c8ccd397db"},"source":["### Importing Required Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_uuid":"03273aed79e22c299518292e5720f4954df13537","execution":{"iopub.execute_input":"2022-05-31T00:31:43.765397Z","iopub.status.busy":"2022-05-31T00:31:43.765107Z","iopub.status.idle":"2022-05-31T00:31:43.770807Z","shell.execute_reply":"2022-05-31T00:31:43.770094Z","shell.execute_reply.started":"2022-05-31T00:31:43.765335Z"},"trusted":true},"outputs":[],"source":["import numpy as np               #for maths\n","import pandas as pd              #for data manipulation\n","import matplotlib.pyplot as plt  #for visualization"]},{"cell_type":"markdown","metadata":{"_uuid":"1b8c6a0c424b4ce91338f8cd49cdf45c863d1c1f"},"source":["###  Load the data"]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"a81dfbf915bbe5f7aeddde8f56031e8395386483","execution":{"iopub.execute_input":"2022-05-31T00:31:43.807218Z","iopub.status.busy":"2022-05-31T00:31:43.806542Z","iopub.status.idle":"2022-05-31T00:31:46.256474Z","shell.execute_reply":"2022-05-31T00:31:46.255210Z","shell.execute_reply.started":"2022-05-31T00:31:43.807162Z"},"trusted":true},"outputs":[],"source":["#data \n","path = r'..Names.csv'\n","data = pd.read_csv(path)\n","\n","#get names from the dataset\n","data['Name'] = data['Name']\n","\n","#get first 10000 names\n","data = np.array(data['Name'][:10000]).reshape(-1,1)\n","\n","#covert the names to lowee case\n","data = [x.lower() for x in data[:,0]]\n","\n","data = np.array(data).reshape(-1,1)"]},{"cell_type":"code","execution_count":3,"metadata":{"_uuid":"7092768c5890de7fff72ed4f2a96a03f0e0dd543","execution":{"iopub.execute_input":"2022-05-31T00:31:46.258346Z","iopub.status.busy":"2022-05-31T00:31:46.257828Z","iopub.status.idle":"2022-05-31T00:31:46.264596Z","shell.execute_reply":"2022-05-31T00:31:46.263554Z","shell.execute_reply.started":"2022-05-31T00:31:46.258304Z"},"trusted":true},"outputs":[],"source":["print(\"Data Shape = {}\".format(data.shape))\n","print()\n","print(\"Lets see some names : \")\n","print(data[1:10])"]},{"cell_type":"markdown","metadata":{"_uuid":"21682a8a6a0644a3f4533755c5d47a3946f647b6"},"source":["### Transforming the names to equal length by adding dots"]},{"cell_type":"code","execution_count":4,"metadata":{"_uuid":"e6e1a392fbb163fb199d9a1f9855618b67c384de","execution":{"iopub.execute_input":"2022-05-31T00:31:46.266128Z","iopub.status.busy":"2022-05-31T00:31:46.265909Z","iopub.status.idle":"2022-05-31T00:31:46.299938Z","shell.execute_reply":"2022-05-31T00:31:46.299283Z","shell.execute_reply.started":"2022-05-31T00:31:46.266097Z"},"trusted":true},"outputs":[],"source":["#to store the transform data\n","transform_data = np.copy(data)\n","\n","#find the max length name\n","max_length = 0\n","for index in range(len(data)):\n","    max_length = max(max_length,len(data[index,0]))\n","\n","#make every name of max length by adding '.'\n","for index in range(len(data)):\n","    length = (max_length - len(data[index,0]))\n","    string = '.'*length\n","    transform_data[index,0] = ''.join([transform_data[index,0],string])"]},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"169aa04299734a309faf4b2517ced8dc458d8e2a","execution":{"iopub.execute_input":"2022-05-31T00:31:46.301065Z","iopub.status.busy":"2022-05-31T00:31:46.300852Z","iopub.status.idle":"2022-05-31T00:31:46.306256Z","shell.execute_reply":"2022-05-31T00:31:46.305191Z","shell.execute_reply.started":"2022-05-31T00:31:46.301027Z"},"trusted":true},"outputs":[],"source":["print(\"Transformed Data\")\n","print(transform_data[1:10])"]},{"cell_type":"markdown","metadata":{"_uuid":"fc16433b33308855028e3437fe16de90636fc9cd"},"source":["### Making the Vocabulary"]},{"cell_type":"code","execution_count":6,"metadata":{"_uuid":"56b3e746aec5bef31f4d076723189d3a3de3bb91","execution":{"iopub.execute_input":"2022-05-31T00:31:46.307729Z","iopub.status.busy":"2022-05-31T00:31:46.307481Z","iopub.status.idle":"2022-05-31T00:31:46.338328Z","shell.execute_reply":"2022-05-31T00:31:46.337525Z","shell.execute_reply.started":"2022-05-31T00:31:46.307660Z"},"trusted":true},"outputs":[],"source":["#to store the vocabulary\n","vocab = list()\n","for name in transform_data[:,0]:\n","    vocab.extend(list(name))\n","\n","vocab = set(vocab)\n","vocab_size = len(vocab)\n","\n","print(\"Vocab size = {}\".format(len(vocab)))\n","print(\"Vocab      = {}\".format(vocab))"]},{"cell_type":"markdown","metadata":{"_uuid":"57d10787e793e123757d863c447e2cc0b505ce40"},"source":["### Mapping characters to ids and ids to characters"]},{"cell_type":"code","execution_count":7,"metadata":{"_uuid":"dacb673988043fb503aaf3b356aacb1a2f923ab2","execution":{"iopub.execute_input":"2022-05-31T00:31:46.340539Z","iopub.status.busy":"2022-05-31T00:31:46.339889Z","iopub.status.idle":"2022-05-31T00:31:46.349386Z","shell.execute_reply":"2022-05-31T00:31:46.348504Z","shell.execute_reply.started":"2022-05-31T00:31:46.340500Z"},"trusted":true},"outputs":[],"source":["#map char to id and id to chars\n","char_id = dict()\n","id_char = dict()\n","\n","for i,char in enumerate(vocab):\n","    char_id[char] = i\n","    id_char[i] = char\n","\n","print('a-{}, 22-{}'.format(char_id['a'],id_char[22]))"]},{"cell_type":"markdown","metadata":{"_uuid":"de643b041387eef2cbf512faa979e50ff9384116"},"source":["### Making the Train dataset\n","\n","Example - names - [['mary.'], ['anna.'] <br>\n","m - [0,0,0,1,0,0] <br>\n","a - [0,0,1,0,0,0] <br>\n","r - [0,1,0,0,0,0] <br>\n","y - [0,0,0,0,1,0] <br>\n","**.** - [1,0,0,0,0,0] <br>\n","\n","'mary.' = [[0,0,0,1,0,0], [0,0,1,0,0,0], [0,1,0,0,0,0], [0,0,0,0,1,0], [1,0,0,0,0,0]] <br>\n","'anna.' = [[0,0,1,0,0,0], [0,0,0,0,0,1], [0,0,0,0,0,1], [0,0,1,0,0,0], [1,0,0,0,0,0]] <br>\n","\n","batch_dataset = [ [[0,0,0,1,0,0],[0,0,1,0,0,0]] , [[0,0,1,0,0,0], [0,0,0,0,0,1]], [[0,1,0,0,0,0], [0,0,0,0,0,1]], [[0,0,0,0,1,0], [0,0,1,0,0,0]] , [ [1,0,0,0,0,0], [1,0,0,0,0,0]] ]"]},{"cell_type":"code","execution_count":8,"metadata":{"_uuid":"1563661dd644e744872a2f59f00349b4fe0bf93d","execution":{"iopub.execute_input":"2022-05-31T00:31:46.351209Z","iopub.status.busy":"2022-05-31T00:31:46.350699Z","iopub.status.idle":"2022-05-31T00:31:46.570006Z","shell.execute_reply":"2022-05-31T00:31:46.569308Z","shell.execute_reply.started":"2022-05-31T00:31:46.351160Z"},"trusted":true},"outputs":[],"source":["# list of batches of size = 20\n","train_dataset = []\n","\n","batch_size = 20\n","\n","#split the trasnform data into batches of 20\n","for i in range(len(transform_data)-batch_size+1):\n","    start = i*batch_size\n","    end = start+batch_size\n","    \n","    #batch data\n","    batch_data = transform_data[start:end]\n","    \n","    if(len(batch_data)!=batch_size):\n","        break\n","        \n","    #convert each char of each name of batch data into one hot encoding\n","    char_list = []\n","    for k in range(len(batch_data[0][0])):\n","        batch_dataset = np.zeros([batch_size,len(vocab)])\n","        for j in range(batch_size):\n","            name = batch_data[j][0]\n","            char_index = char_id[name[k]]\n","            batch_dataset[j,char_index] = 1.0\n","     \n","        #store the ith char's one hot representation of each name in batch_data\n","        char_list.append(batch_dataset)\n","    \n","    #store each char's of every name in batch dataset into train_dataset\n","    train_dataset.append(char_list)"]},{"cell_type":"markdown","metadata":{"_uuid":"6514815063131615058ddcfa273025c43df19a82"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":9,"metadata":{"_uuid":"2e1002eaa8120996b0fb060f7d62de46a35319bb","execution":{"iopub.execute_input":"2022-05-31T00:31:46.571445Z","iopub.status.busy":"2022-05-31T00:31:46.571169Z","iopub.status.idle":"2022-05-31T00:31:46.582914Z","shell.execute_reply":"2022-05-31T00:31:46.581586Z","shell.execute_reply.started":"2022-05-31T00:31:46.571398Z"},"trusted":true},"outputs":[],"source":["#number of input units or embedding size\n","input_units = 100\n","\n","#number of hidden neurons\n","hidden_units = 256\n","\n","#number of output units i.e vocab size\n","output_units = vocab_size\n","\n","#learning rate\n","learning_rate = 0.005\n","\n","#beta1 for V parameters used in Adam Optimizer\n","beta1 = 0.90\n","\n","#beta2 for S parameters used in Adam Optimizer\n","beta2 = 0.99"]},{"cell_type":"markdown","metadata":{"_uuid":"67ef5188422a6df1c27937f27396a158dc0ce081"},"source":["### Activation Functions\n","* **Sigmoid =  1/(1+exp(-X))** \n","* **Tanh    =  (exp(X) - exp(-X)) / (exp(X) + exp(X))**\n","* **Softmax =  exp(X)/(sum(exp(X),1))**\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"71cad984f2f6adce6c40b4b309a7e14c0ce1c1c9","execution":{"iopub.execute_input":"2022-05-31T00:31:46.584987Z","iopub.status.busy":"2022-05-31T00:31:46.584685Z","iopub.status.idle":"2022-05-31T00:31:46.603563Z","shell.execute_reply":"2022-05-31T00:31:46.602830Z","shell.execute_reply.started":"2022-05-31T00:31:46.584926Z"},"trusted":true},"outputs":[],"source":["#Activation Functions\n","#sigmoid\n","def sigmoid(X):\n","    return 1/(1+np.exp(-X))\n","\n","#tanh activation\n","def tanh_activation(X):\n","    return np.tanh(X)\n","\n","#softmax activation\n","def softmax(X):\n","    exp_X = np.exp(X)\n","    exp_X_sum = np.sum(exp_X,axis=1).reshape(-1,1)\n","    exp_X = exp_X/exp_X_sum\n","    return exp_X\n","\n","#derivative of tanh\n","def tanh_derivative(X):\n","    return 1-(X**2)"]},{"cell_type":"markdown","metadata":{"_uuid":"28879cb124e75962321d6cbdb461938a4301c5a1"},"source":["### Initializing Parameters\n","Embeddings Size = 100  <br>\n","Hidden Units = 256  <br>\n","Total INPUT Weights = 100 + 256 = 356 <br>\n","\n","* **LSTM CELL Weights** <br>\n","    * Forget Gate Weights = {356,256}  <br>\n","    * Input Gate Weights  = {356,256}  <br>\n","    * Gate Gate Weights   = {356,256}  <br>\n","    * Output Gate Weights = {356,256}  <br>\n","<br>\n","\n","* **Output CELL Weights** <br>\n","    * Output Weights = {256,27} <br>\n"]},{"cell_type":"code","execution_count":11,"metadata":{"_uuid":"38a224730e5f0e1a1be9ad854b0bb4b6f5f32894","execution":{"iopub.execute_input":"2022-05-31T00:31:46.604922Z","iopub.status.busy":"2022-05-31T00:31:46.604680Z","iopub.status.idle":"2022-05-31T00:31:46.639315Z","shell.execute_reply":"2022-05-31T00:31:46.638509Z","shell.execute_reply.started":"2022-05-31T00:31:46.604871Z"},"trusted":true},"outputs":[],"source":["#initialize parameters\n","def initialize_parameters():\n","    #initialize the parameters with 0 mean and 0.01 standard deviation\n","    mean = 0\n","    std = 0.01\n","    \n","    #lstm cell weights\n","    forget_gate_weights = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n","    input_gate_weights  = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n","    output_gate_weights = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n","    gate_gate_weights   = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n","    \n","    #hidden to output weights (output cell)\n","    hidden_output_weights = np.random.normal(mean,std,(hidden_units,output_units))\n","    \n","    parameters = dict()\n","    parameters['fgw'] = forget_gate_weights\n","    parameters['igw'] = input_gate_weights\n","    parameters['ogw'] = output_gate_weights\n","    parameters['ggw'] = gate_gate_weights\n","    parameters['how'] = hidden_output_weights\n","    \n","    return parameters\n"]},{"cell_type":"markdown","metadata":{"_uuid":"9a288454bfac89da006cba961c72e9904e5cd9c2"},"source":["### LSTM CELL\n","\n","**Equations**\n","* fa = sigmoid(Wf x [xt,at-1]) <br>\n","* ia = sigmoid(Wi x [xt,at-1]) <br>\n","* ga = tanh(Wg x [xt,at-1]) \n","* oa = sigmoid(Wo x [xt,at-1]) \n","* ct = (fa x ct-1) + (ia x ga) \n","* at = oa x tanh(ct) "]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"3a9f7cef02e4ffd2ca690f0575e460473691cd28","execution":{"iopub.execute_input":"2022-05-31T00:31:46.641192Z","iopub.status.busy":"2022-05-31T00:31:46.640618Z","iopub.status.idle":"2022-05-31T00:31:46.710067Z","shell.execute_reply":"2022-05-31T00:31:46.709453Z","shell.execute_reply.started":"2022-05-31T00:31:46.641141Z"},"trusted":true},"outputs":[],"source":["#single lstm cell\n","def lstm_cell(batch_dataset, prev_activation_matrix, prev_cell_matrix, parameters):\n","    #get parameters\n","    fgw = parameters['fgw']\n","    igw = parameters['igw']\n","    ogw = parameters['ogw']\n","    ggw = parameters['ggw']\n","    \n","    #concat batch data and prev_activation matrix\n","    concat_dataset = np.concatenate((batch_dataset,prev_activation_matrix),axis=1)\n","    \n","    #forget gate activations\n","    fa = np.matmul(concat_dataset,fgw)\n","    fa = sigmoid(fa)\n","    \n","    #input gate activations\n","    ia = np.matmul(concat_dataset,igw)\n","    ia = sigmoid(ia)\n","    \n","    #output gate activations\n","    oa = np.matmul(concat_dataset,ogw)\n","    oa = sigmoid(oa)\n","    \n","    #gate gate activations\n","    ga = np.matmul(concat_dataset,ggw)\n","    ga = tanh_activation(ga)\n","    \n","    #new cell memory matrix\n","    cell_memory_matrix = np.multiply(fa,prev_cell_matrix) + np.multiply(ia,ga)\n","    \n","    #current activation matrix\n","    activation_matrix = np.multiply(oa, tanh_activation(cell_memory_matrix))\n","    \n","    #lets store the activations to be used in back prop\n","    lstm_activations = dict()\n","    lstm_activations['fa'] = fa\n","    lstm_activations['ia'] = ia\n","    lstm_activations['oa'] = oa\n","    lstm_activations['ga'] = ga\n","    \n","    return lstm_activations,cell_memory_matrix,activation_matrix"]},{"cell_type":"markdown","metadata":{"_uuid":"3227239971da97d91fff9849fea2cf359ebb8dad"},"source":["### Output Cell\n","\n","Equations \n","* ot = W x at\n","* ot = softmax(ot)"]},{"cell_type":"code","execution_count":13,"metadata":{"_uuid":"8e13f9b6abafc9d582098ad767e90e19bdd8fb20","execution":{"iopub.execute_input":"2022-05-31T00:31:46.711735Z","iopub.status.busy":"2022-05-31T00:31:46.711304Z","iopub.status.idle":"2022-05-31T00:31:46.726992Z","shell.execute_reply":"2022-05-31T00:31:46.726459Z","shell.execute_reply.started":"2022-05-31T00:31:46.711687Z"},"trusted":true},"outputs":[],"source":["def output_cell(activation_matrix,parameters):\n","    #get hidden to output parameters\n","    how = parameters['how']\n","    \n","    #get outputs \n","    output_matrix = np.matmul(activation_matrix,how)\n","    output_matrix = softmax(output_matrix)\n","    \n","    return output_matrix"]},{"cell_type":"markdown","metadata":{"_uuid":"3de27b1ad75c27211f52e3c39cdd6c616ab29a36"},"source":["### Geting corresponding embeddings for the batch dataset"]},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"1de55aa62f5317dcd6adf6841b83c81962c0a646","execution":{"iopub.execute_input":"2022-05-31T00:31:46.728361Z","iopub.status.busy":"2022-05-31T00:31:46.727967Z","iopub.status.idle":"2022-05-31T00:31:46.740933Z","shell.execute_reply":"2022-05-31T00:31:46.739804Z","shell.execute_reply.started":"2022-05-31T00:31:46.728316Z"},"trusted":true},"outputs":[],"source":["def get_embeddings(batch_dataset,embeddings):\n","    embedding_dataset = np.matmul(batch_dataset,embeddings)\n","    return embedding_dataset"]},{"cell_type":"markdown","metadata":{"_uuid":"6ff6b0614522b36694536cc325645a16ca290a78"},"source":["### Forward Propagation\n","\n","Function returns the intermediate ativations in the respective caches:\n","* LSTM Cache :- All lstm cell activation in every cell (fa,ia,ga,oa)\n","* Activation Cache : All activation (a0,a1,a2..)\n","* Cell Cache : All cell activations (c0,c1,c2..\n","* Embedding cache : Embeddings of each batch (e0,e1,e2..)\n","* Output Cache : All output (o1,o2,o3... )"]},{"cell_type":"code","execution_count":15,"metadata":{"_uuid":"b96b7f6ae58183c3691b1b8a096ccc3519116bad","execution":{"iopub.execute_input":"2022-05-31T00:31:46.742829Z","iopub.status.busy":"2022-05-31T00:31:46.742507Z","iopub.status.idle":"2022-05-31T00:31:46.823647Z","shell.execute_reply":"2022-05-31T00:31:46.822829Z","shell.execute_reply.started":"2022-05-31T00:31:46.742768Z"},"trusted":true},"outputs":[],"source":["#forward propagation\n","def forward_propagation(batches,parameters,embeddings):\n","    #get batch size\n","    batch_size = batches[0].shape[0]\n","    \n","    #to store the activations of all the unrollings.\n","    lstm_cache = dict()                 #lstm cache\n","    activation_cache = dict()           #activation cache \n","    cell_cache = dict()                 #cell cache\n","    output_cache = dict()               #output cache\n","    embedding_cache = dict()            #embedding cache \n","    \n","    #initial activation_matrix(a0) and cell_matrix(c0)\n","    a0 = np.zeros([batch_size,hidden_units],dtype=np.float32)\n","    c0 = np.zeros([batch_size,hidden_units],dtype=np.float32)\n","    \n","    #store the initial activations in cache\n","    activation_cache['a0'] = a0\n","    cell_cache['c0'] = c0\n","    \n","    #unroll the names\n","    for i in range(len(batches)-1):\n","        #get first first character batch\n","        batch_dataset = batches[i]\n","        \n","        #get embeddings \n","        batch_dataset = get_embeddings(batch_dataset,embeddings)\n","        embedding_cache['emb'+str(i)] = batch_dataset\n","        \n","        #lstm cell\n","        lstm_activations,ct,at = lstm_cell(batch_dataset,a0,c0,parameters)\n","        \n","        #output cell\n","        ot = output_cell(at,parameters)\n","        \n","        #store the time 't' activations in caches\n","        lstm_cache['lstm' + str(i+1)]  = lstm_activations\n","        activation_cache['a'+str(i+1)] = at\n","        cell_cache['c' + str(i+1)] = ct\n","        output_cache['o'+str(i+1)] = ot\n","        \n","        #update a0 and c0 to new 'at' and 'ct' for next lstm cell\n","        a0 = at\n","        c0 = ct\n","        \n","    return embedding_cache,lstm_cache,activation_cache,cell_cache,output_cache"]},{"cell_type":"markdown","metadata":{"_uuid":"ccece450fafd45cd88b68dea56b3ab15b9161b4d"},"source":["### Calculating the Loss, Perplexity, and Accuracy\n","**Loss**\n","* Loss at time t = -sum(Y x log(d) + (1-Y) x log(1-pred)))/m\n","* Overall Loss = **∑**(Loss(t)) sum of all losses at each time step 't'\n","\n","**Perplexity**\n","* Probability Product = **∏**(prob(pred_char)) for each char in name\n","* Perplexity = (1/probability_product) ^ (1/n) where n in number of chars in name\n","\n","**Accuracy**\n","* Accuracy(t) = (Y==predictions,axis=1) for all time steps\n","* Accuracy = ((**∑**Acc(t))/batch_size)/n for all time steps, n is number of chars in name"]},{"cell_type":"code","execution_count":16,"metadata":{"_uuid":"43318e7340569b2421b9299c8fb958a0092e5713","execution":{"iopub.execute_input":"2022-05-31T00:31:46.825404Z","iopub.status.busy":"2022-05-31T00:31:46.824996Z","iopub.status.idle":"2022-05-31T00:31:46.872159Z","shell.execute_reply":"2022-05-31T00:31:46.871488Z","shell.execute_reply.started":"2022-05-31T00:31:46.825363Z"},"trusted":true},"outputs":[],"source":["#calculate loss, perplexity and accuracy\n","def cal_loss_accuracy(batch_labels,output_cache):\n","    loss = 0  #to sum loss for each time step\n","    acc  = 0  #to sum acc for each time step \n","    prob = 1  #probability product of each time step predicted char\n","    \n","    #batch size\n","    batch_size = batch_labels[0].shape[0]\n","    \n","    #loop through each time step\n","    for i in range(1,len(output_cache)+1):\n","        #get true labels and predictions\n","        labels = batch_labels[i]\n","        pred = output_cache['o'+str(i)]\n","        \n","        prob = np.multiply(prob,np.sum(np.multiply(labels,pred),axis=1).reshape(-1,1))\n","        loss += np.sum((np.multiply(labels,np.log(pred)) + np.multiply(1-labels,np.log(1-pred))),axis=1).reshape(-1,1)\n","        acc  += np.array(np.argmax(labels,1)==np.argmax(pred,1),dtype=np.float32).reshape(-1,1)\n","    \n","    #calculate perplexity loss and accuracy\n","    perplexity = np.sum((1/prob)**(1/len(output_cache)))/batch_size\n","    loss = np.sum(loss)*(-1/batch_size)\n","    acc  = np.sum(acc)/(batch_size)\n","    acc = acc/len(output_cache)\n","    \n","    return perplexity,loss,acc"]},{"cell_type":"markdown","metadata":{"_uuid":"50f0382ea6d886c08b74c99f40c5fe4658d102f4"},"source":["### Calculate Output Cell Errors for each time step\n","* Output Error Cache :- to store output error for each time step\n","* Activation Error Cache : to store activation error for each time step"]},{"cell_type":"code","execution_count":17,"metadata":{"_uuid":"bbc7499117d4dca92c550d5eae960d0b9bad2b32","execution":{"iopub.execute_input":"2022-05-31T00:31:46.873658Z","iopub.status.busy":"2022-05-31T00:31:46.873298Z","iopub.status.idle":"2022-05-31T00:31:46.902171Z","shell.execute_reply":"2022-05-31T00:31:46.901021Z","shell.execute_reply.started":"2022-05-31T00:31:46.873614Z"},"trusted":true},"outputs":[],"source":["#calculate output cell errors\n","def calculate_output_cell_error(batch_labels,output_cache,parameters):\n","    #to store the output errors for each time step\n","    output_error_cache = dict()\n","    activation_error_cache = dict()\n","    how = parameters['how']\n","    \n","    #loop through each time step\n","    for i in range(1,len(output_cache)+1):\n","        #get true and predicted labels\n","        labels = batch_labels[i]\n","        pred = output_cache['o'+str(i)]\n","        \n","        #calculate the output_error for time step 't'\n","        error_output = pred - labels\n","        \n","        #calculate the activation error for time step 't'\n","        error_activation = np.matmul(error_output,how.T)\n","        \n","        #store the output and activation error in dict\n","        output_error_cache['eo'+str(i)] = error_output\n","        activation_error_cache['ea'+str(i)] = error_activation\n","        \n","    return output_error_cache,activation_error_cache"]},{"cell_type":"markdown","metadata":{"_uuid":"9cc14608467e9fa9eba4b36c5e1d2d24a80852a8"},"source":["### Calculating Single LSTM CELL Error"]},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"2fb6e8f9cae63d99adb92c79fea9f6d3a69d7633","execution":{"iopub.execute_input":"2022-05-31T00:31:46.903577Z","iopub.status.busy":"2022-05-31T00:31:46.903242Z","iopub.status.idle":"2022-05-31T00:31:47.086237Z","shell.execute_reply":"2022-05-31T00:31:47.085602Z","shell.execute_reply.started":"2022-05-31T00:31:46.903530Z"},"trusted":true},"outputs":[],"source":["#calculate error for single lstm cell\n","def calculate_single_lstm_cell_error(activation_output_error,next_activation_error,next_cell_error,parameters,lstm_activation,cell_activation,prev_cell_activation):\n","    #activation error =  error coming from output cell and error coming from the next lstm cell\n","    activation_error = activation_output_error + next_activation_error\n","    \n","    #output gate error\n","    oa = lstm_activation['oa']\n","    eo = np.multiply(activation_error,tanh_activation(cell_activation))\n","    eo = np.multiply(np.multiply(eo,oa),1-oa)\n","    \n","    #cell activation error\n","    cell_error = np.multiply(activation_error,oa)\n","    cell_error = np.multiply(cell_error,tanh_derivative(tanh_activation(cell_activation)))\n","    #error also coming from next lstm cell \n","    cell_error += next_cell_error\n","    \n","    #input gate error\n","    ia = lstm_activation['ia']\n","    ga = lstm_activation['ga']\n","    ei = np.multiply(cell_error,ga)\n","    ei = np.multiply(np.multiply(ei,ia),1-ia)\n","    \n","    #gate gate error\n","    eg = np.multiply(cell_error,ia)\n","    eg = np.multiply(eg,tanh_derivative(ga))\n","    \n","    #forget gate error\n","    fa = lstm_activation['fa']\n","    ef = np.multiply(cell_error,prev_cell_activation)\n","    ef = np.multiply(np.multiply(ef,fa),1-fa)\n","    \n","    #prev cell error\n","    prev_cell_error = np.multiply(cell_error,fa)\n","    \n","    #get parameters\n","    fgw = parameters['fgw']\n","    igw = parameters['igw']\n","    ggw = parameters['ggw']\n","    ogw = parameters['ogw']\n","    \n","    #embedding + hidden activation error\n","    embed_activation_error = np.matmul(ef,fgw.T)\n","    embed_activation_error += np.matmul(ei,igw.T)\n","    embed_activation_error += np.matmul(eo,ogw.T)\n","    embed_activation_error += np.matmul(eg,ggw.T)\n","    \n","    input_hidden_units = fgw.shape[0]\n","    hidden_units = fgw.shape[1]\n","    input_units = input_hidden_units - hidden_units\n","    \n","    #prev activation error\n","    prev_activation_error = embed_activation_error[:,input_units:]\n","    \n","    #input error (embedding error)\n","    embed_error = embed_activation_error[:,:input_units]\n","    \n","    #store lstm error\n","    lstm_error = dict()\n","    lstm_error['ef'] = ef\n","    lstm_error['ei'] = ei\n","    lstm_error['eo'] = eo\n","    lstm_error['eg'] = eg\n","    \n","    return prev_activation_error,prev_cell_error,embed_error,lstm_error"]},{"cell_type":"markdown","metadata":{"_uuid":"ec190975e8b1df1ae7dd03d1c87630ef00f66797"},"source":["### Calculating Output Cell Derivatives for each time step"]},{"cell_type":"code","execution_count":19,"metadata":{"_uuid":"30d5bbe3137c06c647a8f7c337a68449d680f526","execution":{"iopub.execute_input":"2022-05-31T00:31:47.087818Z","iopub.status.busy":"2022-05-31T00:31:47.087521Z","iopub.status.idle":"2022-05-31T00:31:47.110498Z","shell.execute_reply":"2022-05-31T00:31:47.109409Z","shell.execute_reply.started":"2022-05-31T00:31:47.087750Z"},"trusted":true},"outputs":[],"source":["#calculate output cell derivatives\n","def calculate_output_cell_derivatives(output_error_cache,activation_cache,parameters):\n","    #to store the sum of derivatives from each time step\n","    dhow = np.zeros(parameters['how'].shape)\n","    \n","    batch_size = activation_cache['a1'].shape[0]\n","    \n","    #loop through the time steps \n","    for i in range(1,len(output_error_cache)+1):\n","        #get output error\n","        output_error = output_error_cache['eo' + str(i)]\n","        \n","        #get input activation\n","        activation = activation_cache['a'+str(i)]\n","        \n","        #cal derivative and summing up!\n","        dhow += np.matmul(activation.T,output_error)/batch_size\n","        \n","    return dhow"]},{"cell_type":"markdown","metadata":{"_uuid":"188c17e489c24436903b29683ba7c94ea7d072fd"},"source":["### Calculating LSTM CELL Derivatives for each time step"]},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"180778f81b4f2db577f7ab39fafa7ce7d0775518","execution":{"iopub.execute_input":"2022-05-31T00:31:47.112276Z","iopub.status.busy":"2022-05-31T00:31:47.111943Z","iopub.status.idle":"2022-05-31T00:31:47.150644Z","shell.execute_reply":"2022-05-31T00:31:47.149751Z","shell.execute_reply.started":"2022-05-31T00:31:47.112226Z"},"trusted":true},"outputs":[],"source":["#calculate derivatives for single lstm cell\n","def calculate_single_lstm_cell_derivatives(lstm_error,embedding_matrix,activation_matrix):\n","    #get error for single time step\n","    ef = lstm_error['ef']\n","    ei = lstm_error['ei']\n","    eo = lstm_error['eo']\n","    eg = lstm_error['eg']\n","    \n","    #get input activations for this time step\n","    concat_matrix = np.concatenate((embedding_matrix,activation_matrix),axis=1)\n","    \n","    batch_size = embedding_matrix.shape[0]\n","    \n","    #cal derivatives for this time step\n","    dfgw = np.matmul(concat_matrix.T,ef)/batch_size\n","    digw = np.matmul(concat_matrix.T,ei)/batch_size\n","    dogw = np.matmul(concat_matrix.T,eo)/batch_size\n","    dggw = np.matmul(concat_matrix.T,eg)/batch_size\n","    \n","    #store the derivatives for this time step in dict\n","    derivatives = dict()\n","    derivatives['dfgw'] = dfgw\n","    derivatives['digw'] = digw\n","    derivatives['dogw'] = dogw\n","    derivatives['dggw'] = dggw\n","    \n","    return derivatives"]},{"cell_type":"markdown","metadata":{"_uuid":"0034c9d5bab9f30909d91c5d877ae255ded9ddca"},"source":["### Backward Propagation\n","\n","* Apply chain rule and calculate the errors for each time step\n","* Store the deivatives in **derivatives** dict"]},{"cell_type":"code","execution_count":21,"metadata":{"_uuid":"22e0936aad852146820c5c9c37c5bab1d6f4938a","execution":{"iopub.execute_input":"2022-05-31T00:31:47.152550Z","iopub.status.busy":"2022-05-31T00:31:47.152227Z","iopub.status.idle":"2022-05-31T00:31:47.297390Z","shell.execute_reply":"2022-05-31T00:31:47.295932Z","shell.execute_reply.started":"2022-05-31T00:31:47.152484Z"},"trusted":true},"outputs":[],"source":["#backpropagation\n","def backward_propagation(batch_labels,embedding_cache,lstm_cache,activation_cache,cell_cache,output_cache,parameters):\n","    #calculate output errors \n","    output_error_cache,activation_error_cache = calculate_output_cell_error(batch_labels,output_cache,parameters)\n","    \n","    #to store lstm error for each time step\n","    lstm_error_cache = dict()\n","    \n","    #to store embeding errors for each time step\n","    embedding_error_cache = dict()\n","    \n","    # next activation error \n","    # next cell error  \n","    #for last cell will be zero\n","    eat = np.zeros(activation_error_cache['ea1'].shape)\n","    ect = np.zeros(activation_error_cache['ea1'].shape)\n","    \n","    #calculate all lstm cell errors (going from last time-step to the first time step)\n","    for i in range(len(lstm_cache),0,-1):\n","        #calculate the lstm errors for this time step 't'\n","        pae,pce,ee,le = calculate_single_lstm_cell_error(activation_error_cache['ea'+str(i)],eat,ect,parameters,lstm_cache['lstm'+str(i)],cell_cache['c'+str(i)],cell_cache['c'+str(i-1)])\n","        \n","        #store the lstm error in dict\n","        lstm_error_cache['elstm'+str(i)] = le\n","        \n","        #store the embedding error in dict\n","        embedding_error_cache['eemb'+str(i-1)] = ee\n","        \n","        #update the next activation error and next cell error for previous cell\n","        eat = pae\n","        ect = pce\n","    \n","    \n","    #calculate output cell derivatives\n","    derivatives = dict()\n","    derivatives['dhow'] = calculate_output_cell_derivatives(output_error_cache,activation_cache,parameters)\n","    \n","    #calculate lstm cell derivatives for each time step and store in lstm_derivatives dict\n","    lstm_derivatives = dict()\n","    for i in range(1,len(lstm_error_cache)+1):\n","        lstm_derivatives['dlstm'+str(i)] = calculate_single_lstm_cell_derivatives(lstm_error_cache['elstm'+str(i)],embedding_cache['emb'+str(i-1)],activation_cache['a'+str(i-1)])\n","    \n","    #initialize the derivatives to zeros \n","    derivatives['dfgw'] = np.zeros(parameters['fgw'].shape)\n","    derivatives['digw'] = np.zeros(parameters['igw'].shape)\n","    derivatives['dogw'] = np.zeros(parameters['ogw'].shape)\n","    derivatives['dggw'] = np.zeros(parameters['ggw'].shape)\n","    \n","    #sum up the derivatives for each time step\n","    for i in range(1,len(lstm_error_cache)+1):\n","        derivatives['dfgw'] += lstm_derivatives['dlstm'+str(i)]['dfgw']\n","        derivatives['digw'] += lstm_derivatives['dlstm'+str(i)]['digw']\n","        derivatives['dogw'] += lstm_derivatives['dlstm'+str(i)]['dogw']\n","        derivatives['dggw'] += lstm_derivatives['dlstm'+str(i)]['dggw']\n","    \n","    return derivatives,embedding_error_cache"]},{"cell_type":"markdown","metadata":{"_uuid":"92f90ed48cb1d16c58952c06a6605c9bec23ed17"},"source":["### Adam Optimizer\n","Using Exponentially Weighted Averages <br>\n","* Vdw = beta1 x Vdw + (1-beta1) x (dw)   \n","* Sdw = beta2 x Sdw + (1-beta2) x dw^2\n","* W = W - learning_rate x ( Vdw/ (sqrt(Sdw)+1e-7) )"]},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"cb5eec4b78051a31bf025a418a2536ee9509f82c","execution":{"iopub.execute_input":"2022-05-31T00:31:47.298938Z","iopub.status.busy":"2022-05-31T00:31:47.298691Z","iopub.status.idle":"2022-05-31T00:31:47.561351Z","shell.execute_reply":"2022-05-31T00:31:47.560314Z","shell.execute_reply.started":"2022-05-31T00:31:47.298893Z"},"trusted":true},"outputs":[],"source":["#update the parameters using adam optimizer\n","#adam optimization\n","def update_parameters(parameters,derivatives,V,S,t):\n","    #get derivatives\n","    dfgw = derivatives['dfgw']\n","    digw = derivatives['digw']\n","    dogw = derivatives['dogw']\n","    dggw = derivatives['dggw']\n","    dhow = derivatives['dhow']\n","    \n","    #get parameters\n","    fgw = parameters['fgw']\n","    igw = parameters['igw']\n","    ogw = parameters['ogw']\n","    ggw = parameters['ggw']\n","    how = parameters['how']\n","    \n","    #get V parameters\n","    vfgw = V['vfgw']\n","    vigw = V['vigw']\n","    vogw = V['vogw']\n","    vggw = V['vggw']\n","    vhow = V['vhow']\n","    \n","    #get S parameters\n","    sfgw = S['sfgw']\n","    sigw = S['sigw']\n","    sogw = S['sogw']\n","    sggw = S['sggw']\n","    show = S['show']\n","    \n","    #calculate the V parameters from V and current derivatives\n","    vfgw = (beta1*vfgw + (1-beta1)*dfgw)\n","    vigw = (beta1*vigw + (1-beta1)*digw)\n","    vogw = (beta1*vogw + (1-beta1)*dogw)\n","    vggw = (beta1*vggw + (1-beta1)*dggw)\n","    vhow = (beta1*vhow + (1-beta1)*dhow)\n","    \n","    #calculate the S parameters from S and current derivatives\n","    sfgw = (beta2*sfgw + (1-beta2)*(dfgw**2))\n","    sigw = (beta2*sigw + (1-beta2)*(digw**2))\n","    sogw = (beta2*sogw + (1-beta2)*(dogw**2))\n","    sggw = (beta2*sggw + (1-beta2)*(dggw**2))\n","    show = (beta2*show + (1-beta2)*(dhow**2))\n","    \n","    #update the parameters\n","    fgw = fgw - learning_rate*((vfgw)/(np.sqrt(sfgw) + 1e-6))\n","    igw = igw - learning_rate*((vigw)/(np.sqrt(sigw) + 1e-6))\n","    ogw = ogw - learning_rate*((vogw)/(np.sqrt(sogw) + 1e-6))\n","    ggw = ggw - learning_rate*((vggw)/(np.sqrt(sggw) + 1e-6))\n","    how = how - learning_rate*((vhow)/(np.sqrt(show) + 1e-6))\n","    \n","    #store the new weights\n","    parameters['fgw'] = fgw\n","    parameters['igw'] = igw\n","    parameters['ogw'] = ogw\n","    parameters['ggw'] = ggw\n","    parameters['how'] = how\n","    \n","    #store the new V parameters\n","    V['vfgw'] = vfgw \n","    V['vigw'] = vigw \n","    V['vogw'] = vogw \n","    V['vggw'] = vggw\n","    V['vhow'] = vhow\n","    \n","    #store the s parameters\n","    S['sfgw'] = sfgw \n","    S['sigw'] = sigw \n","    S['sogw'] = sogw \n","    S['sggw'] = sggw\n","    S['show'] = show\n","    \n","    return parameters,V,S    "]},{"cell_type":"markdown","metadata":{"_uuid":"3ff41245f89d4af31bc5e8965cf83525c4694fe5"},"source":["### Updating the embeddings"]},{"cell_type":"code","execution_count":23,"metadata":{"_uuid":"3d16352990b74ccc2392ac9ee4891b181470f5ff","execution":{"iopub.execute_input":"2022-05-31T00:31:47.562992Z","iopub.status.busy":"2022-05-31T00:31:47.562754Z","iopub.status.idle":"2022-05-31T00:31:47.578821Z","shell.execute_reply":"2022-05-31T00:31:47.578096Z","shell.execute_reply.started":"2022-05-31T00:31:47.562929Z"},"trusted":true},"outputs":[],"source":["#update the Embeddings\n","def update_embeddings(embeddings,embedding_error_cache,batch_labels):\n","    #to store the embeddings derivatives\n","    embedding_derivatives = np.zeros(embeddings.shape)\n","    \n","    batch_size = batch_labels[0].shape[0]\n","    \n","    #sum the embedding derivatives for each time step\n","    for i in range(len(embedding_error_cache)):\n","        embedding_derivatives += np.matmul(batch_labels[i].T,embedding_error_cache['eemb'+str(i)])/batch_size\n","    \n","    #update the embeddings\n","    embeddings = embeddings - learning_rate*embedding_derivatives\n","    return embeddings"]},{"cell_type":"markdown","metadata":{"_uuid":"17f5d44fc69c4694a0d0698588df44a3dce9d9c2"},"source":["### Functions to Initialize the V and S parameters for Adam Optimizer"]},{"cell_type":"code","execution_count":24,"metadata":{"_uuid":"c188a724be12aa28481d16fb62e154e77c376570","execution":{"iopub.execute_input":"2022-05-31T00:31:47.580487Z","iopub.status.busy":"2022-05-31T00:31:47.580150Z","iopub.status.idle":"2022-05-31T00:31:47.639804Z","shell.execute_reply":"2022-05-31T00:31:47.639032Z","shell.execute_reply.started":"2022-05-31T00:31:47.580418Z"},"trusted":true},"outputs":[],"source":["def initialize_V(parameters):\n","    Vfgw = np.zeros(parameters['fgw'].shape)\n","    Vigw = np.zeros(parameters['igw'].shape)\n","    Vogw = np.zeros(parameters['ogw'].shape)\n","    Vggw = np.zeros(parameters['ggw'].shape)\n","    Vhow = np.zeros(parameters['how'].shape)\n","    \n","    V = dict()\n","    V['vfgw'] = Vfgw\n","    V['vigw'] = Vigw\n","    V['vogw'] = Vogw\n","    V['vggw'] = Vggw\n","    V['vhow'] = Vhow\n","    return V\n","\n","def initialize_S(parameters):\n","    Sfgw = np.zeros(parameters['fgw'].shape)\n","    Sigw = np.zeros(parameters['igw'].shape)\n","    Sogw = np.zeros(parameters['ogw'].shape)\n","    Sggw = np.zeros(parameters['ggw'].shape)\n","    Show = np.zeros(parameters['how'].shape)\n","    \n","    S = dict()\n","    S['sfgw'] = Sfgw\n","    S['sigw'] = Sigw\n","    S['sogw'] = Sogw\n","    S['sggw'] = Sggw\n","    S['show'] = Show\n","    return S"]},{"cell_type":"markdown","metadata":{"_uuid":"1530f469e8e81bb04e0f88fe5c40cb3ba06e0735"},"source":["### Train Function\n","\n","1. Initialize Parameters\n","2. Forward Propagation\n","3. Calculate Loss, Perplexity and Accuracy\n","4. Backward Propagation\n","5. Update the Parameters and Embeddings\n","\n","Batch Size = 20\n","Repeat the steps 2-5 for each batch!"]},{"cell_type":"code","execution_count":25,"metadata":{"_uuid":"a5816f86b11d6ff83e5b8b7717fcee5f8e8bb040","execution":{"iopub.execute_input":"2022-05-31T00:31:47.641159Z","iopub.status.busy":"2022-05-31T00:31:47.640829Z","iopub.status.idle":"2022-05-31T00:31:47.746702Z","shell.execute_reply":"2022-05-31T00:31:47.746025Z","shell.execute_reply.started":"2022-05-31T00:31:47.641122Z"},"trusted":true},"outputs":[],"source":["#train function\n","def train(train_dataset,iters=1000,batch_size=20):\n","    #initalize the parameters\n","    parameters = initialize_parameters()\n","    \n","    #initialize the V and S parameters for Adam\n","    V = initialize_V(parameters)\n","    S = initialize_S(parameters)\n","    \n","    #generate the random embeddings\n","    embeddings = np.random.normal(0,0.01,(len(vocab),input_units))\n","    \n","    #to store the Loss, Perplexity and Accuracy for each batch\n","    J = []\n","    P = []\n","    A = []\n","    \n","    \n","    for step in range(iters):\n","        #get batch dataset\n","        index = step%len(train_dataset)\n","        batches = train_dataset[index]\n","        \n","        #forward propagation\n","        embedding_cache,lstm_cache,activation_cache,cell_cache,output_cache = forward_propagation(batches,parameters,embeddings)\n","        \n","        #calculate the loss, perplexity and accuracy\n","        perplexity,loss,acc = cal_loss_accuracy(batches,output_cache)\n","        \n","        #backward propagation\n","        derivatives,embedding_error_cache = backward_propagation(batches,embedding_cache,lstm_cache,activation_cache,cell_cache,output_cache,parameters)\n","        \n","        #update the parameters\n","        parameters,V,S = update_parameters(parameters,derivatives,V,S,step)\n","        \n","        #update the embeddings\n","        embeddings = update_embeddings(embeddings,embedding_error_cache,batches)\n","        \n","        \n","        J.append(loss)\n","        P.append(perplexity)\n","        A.append(acc)\n","        \n","        #print loss, accuracy and perplexity\n","        if(step%1000==0):\n","            print(\"For Single Batch :\")\n","            print('Step       = {}'.format(step))\n","            print('Loss       = {}'.format(round(loss,2)))\n","            print('Perplexity = {}'.format(round(perplexity,2)))\n","            print('Accuracy   = {}'.format(round(acc*100,2)))\n","            print()\n","    \n","    return embeddings, parameters,J,P,A"]},{"cell_type":"markdown","metadata":{"_uuid":"ea0d72a85111f3d78474c426a9ca570030093c91"},"source":["### Training the dataset"]},{"cell_type":"code","execution_count":26,"metadata":{"_uuid":"fff95d703395812c87fafc59bccc9c867c73c32e","execution":{"iopub.execute_input":"2022-05-31T00:31:47.747987Z","iopub.status.busy":"2022-05-31T00:31:47.747741Z","iopub.status.idle":"2022-05-31T00:42:35.998713Z","shell.execute_reply":"2022-05-31T00:42:35.998120Z","shell.execute_reply.started":"2022-05-31T00:31:47.747920Z"},"trusted":true},"outputs":[],"source":["embeddings,parameters,J,P,A = train(train_dataset,iters=8001)"]},{"cell_type":"markdown","metadata":{"_uuid":"cc63678f7f15d413a44fd625af8695daa48e0852"},"source":["### Graphical Representation\n","\n","*  Plotted average loss of 30 batches, average perplexity of 30 batches, and average accuracy of 30 batches."]},{"cell_type":"code","execution_count":27,"metadata":{"_uuid":"2a08189462b703684c38c188cf8a80cdfc57528f","execution":{"iopub.execute_input":"2022-05-31T00:42:36.000500Z","iopub.status.busy":"2022-05-31T00:42:36.000086Z","iopub.status.idle":"2022-05-31T00:42:36.437863Z","shell.execute_reply":"2022-05-31T00:42:36.436709Z","shell.execute_reply.started":"2022-05-31T00:42:36.000433Z"},"trusted":true},"outputs":[],"source":["avg_loss = list()\n","avg_acc = list()\n","avg_perp = list()\n","i = 0\n","while(i<len(J)):\n","    avg_loss.append(np.mean(J[i:i+30]))\n","    avg_acc.append(np.mean(A[i:i+30]))\n","    avg_perp.append(np.mean(P[i:i+30]))\n","    i += 30\n","\n","plt.plot(list(range(len(avg_loss))),avg_loss)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"Loss (Avg of 30 batches)\")\n","plt.title(\"Loss Graph\")\n","plt.show()\n","\n","plt.plot(list(range(len(avg_perp))),avg_perp)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"Perplexity (Avg of 30 batches)\")\n","plt.title(\"Perplexity Graph\")\n","plt.show()\n","\n","plt.plot(list(range(len(avg_acc))),avg_acc)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"Accuracy (Avg of 30 batches)\")\n","plt.title(\"Accuracy Graph\")\n","plt.show()    "]},{"cell_type":"markdown","metadata":{"_uuid":"bb8738d78ad60f6fe16038b32a29630919e91976"},"source":["### Making predictions"]},{"cell_type":"code","execution_count":28,"metadata":{"_uuid":"09ac989d49560b820a0d23de90707f59ec8700b5","execution":{"iopub.execute_input":"2022-05-31T00:42:36.586612Z","iopub.status.busy":"2022-05-31T00:42:36.586280Z","iopub.status.idle":"2022-05-31T00:42:36.726798Z","shell.execute_reply":"2022-05-31T00:42:36.726085Z","shell.execute_reply.started":"2022-05-31T00:42:36.586550Z"},"trusted":true},"outputs":[],"source":["#predict\n","def predict(parameters,embeddings,id_char,vocab_size):\n","    #to store some predicted names\n","    names = []\n","    \n","    #predict 20 names\n","    for i in range(20):\n","        #initial activation_matrix(a0) and cell_matrix(c0)\n","        a0 = np.zeros([1,hidden_units],dtype=np.float32)\n","        c0 = np.zeros([1,hidden_units],dtype=np.float32)\n","\n","        #initalize blank name\n","        name = ''\n","        \n","        #make a batch dataset of single char\n","        batch_dataset = np.zeros([1,vocab_size])\n","        \n","        #get random start character\n","        index = np.random.randint(0,27,1)[0]\n","        \n","        #make that index 1.0\n","        batch_dataset[0,index] = 1.0\n","        \n","        #add first char to name\n","        name += id_char[index]\n","        \n","        #get char from id_char dict\n","        char = id_char[index]\n","        \n","        #loop until algo predicts '.'\n","        while(char!='.'):\n","            #get embeddings\n","            batch_dataset = get_embeddings(batch_dataset,embeddings)\n","\n","            #lstm cell\n","            lstm_activations,ct,at = lstm_cell(batch_dataset,a0,c0,parameters)\n","\n","            #output cell\n","            ot = output_cell(at,parameters)\n","            \n","            #either select random.choice ot np.argmax\n","            pred = np.random.choice(27,1,p=ot[0])[0]\n","            \n","            #get predicted char index\n","            #pred = np.argmax(ot)\n","                \n","            #add char to name\n","            name += id_char[pred]\n","            \n","            char = id_char[pred]\n","            \n","            #change the batch_dataset to this new predicted char\n","            batch_dataset = np.zeros([1,vocab_size])\n","            batch_dataset[0,pred] = 1.0\n","\n","            #update a0 and c0 to new 'at' and 'ct' for next lstm cell\n","            a0 = at\n","            c0 = ct\n","            \n","        #append the predicted name to names list\n","        names.append(name)\n","        \n","    return names"]},{"cell_type":"markdown","metadata":{"_uuid":"d9c26137d2c08c22efe4d07c0762f4db891c8bc2"},"source":["### Predicting Names using Argmax"]},{"cell_type":"code","execution_count":29,"metadata":{"_uuid":"6ae3c2a1cd42afea050a9612ab07024d2ec5e90d","execution":{"iopub.execute_input":"2022-05-31T00:42:36.728599Z","iopub.status.busy":"2022-05-31T00:42:36.728286Z","iopub.status.idle":"2022-05-31T00:42:36.783612Z","shell.execute_reply":"2022-05-31T00:42:36.782938Z","shell.execute_reply.started":"2022-05-31T00:42:36.728532Z"},"trusted":true},"outputs":[],"source":["predict(parameters,embeddings,id_char,vocab_size)"]},{"cell_type":"markdown","metadata":{"_uuid":"eef286da051a728c715d1124bd37f0b0df106a57"},"source":["### Predicting using Random.Choice"]},{"cell_type":"code","execution_count":30,"metadata":{"_uuid":"e2dc3a10778120b483f8b125f03126a6d9f71561","execution":{"iopub.execute_input":"2022-05-31T00:42:36.786243Z","iopub.status.busy":"2022-05-31T00:42:36.785924Z","iopub.status.idle":"2022-05-31T00:42:36.828146Z","shell.execute_reply":"2022-05-31T00:42:36.827130Z","shell.execute_reply.started":"2022-05-31T00:42:36.786194Z"},"trusted":true},"outputs":[],"source":["predict(parameters,embeddings,id_char,vocab_size)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}
