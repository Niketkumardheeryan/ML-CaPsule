{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CHATBOT USING RASA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dKOnShnQgmX"
      },
      "source": [
        "Import rasa_core, rasa_nlu spacy and sys\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "9Fe3sBaQTTl2"
      },
      "outputs": [],
      "source": [
        "import rasa_core\n",
        "import rasa_nlu\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "s6t_iVs3bMHt"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "python = sys.executable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWiAfbaWRdUz"
      },
      "source": [
        "Declaration of intent and sample words/phrases/sentences which refer to the intention decleared, which will be stored inside nlu.md. In other words, these are sample phrases whcih the chatbot will learn from for each intent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOjwGdZLndBN",
        "outputId": "8eb7b309-5739-415c-8091-44d53d5ecc19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing 'nlu_md' (str) to file 'nlu.md'.\n"
          ]
        }
      ],
      "source": [
        "# Writing various intents with examples to nlu.md file\n",
        "\n",
        "nlu_md = \"\"\"\n",
        "## intent:greet\n",
        "- hey\n",
        "- hello there\n",
        "- hi\n",
        "- hello there\n",
        "- good morning\n",
        "- good evening\n",
        "- how far\n",
        "- hey there\n",
        "- whats up\n",
        "- hey dude\n",
        "- goodmorning\n",
        "- goodevening\n",
        "- good afternoon\n",
        "\n",
        "## intent:goodbye\n",
        "- good by\n",
        "- later\n",
        "- good night\n",
        "- good afternoon\n",
        "- bye\n",
        "- goodbye\n",
        "- have a nice day\n",
        "- see you around\n",
        "- bye bye\n",
        "- see you later\n",
        "\n",
        "## intent:thanks\n",
        "- thanks\n",
        "- thank you\n",
        "- appreciated\n",
        "- gracias\n",
        "\n",
        "\n",
        "## intent:directions\n",
        "- how do i get to\n",
        "- i need to get to\n",
        "- is there a bus to\n",
        "- how i go take reach\n",
        "- I need directions to\n",
        "- how do i get a cab\n",
        "- where can i get a taxi\n",
        "- where can i get a bus\n",
        "-i need to get somewhere\n",
        "-I am going somewhere\n",
        "\n",
        "## intent:choosing_item\n",
        "- 1\n",
        "- 2\n",
        "- 3\n",
        "- 4\n",
        "- 5\n",
        "- 6\n",
        "- 7\n",
        "\n",
        "## intent:accomodation_enquiry\n",
        "- Where is the nearest hotel ?\n",
        "- is there a hotel near by ?\n",
        "- shey hotel they this area ?\n",
        "- Where i fit crash for here ?\n",
        "- i want to get to a hotel\n",
        "- i need to get to a hotel\n",
        "- where can i spend the night ?\n",
        "\n",
        "## intent: restaurant_enquiry\n",
        "- i need to get food\n",
        "- i am hungry\n",
        "- where is the restaurant ?\n",
        "- is there a restaurant ?\n",
        "- where can i get water ?\n",
        "- where i fit buy food for here ?\n",
        "- is there a food court nearby ?\n",
        "- where them they sell food ?\n",
        "- I want chop\n",
        "- where is the nearest shop?\n",
        "- where can i eat ?\n",
        "- i need to eat \n",
        "- are there eatries around ?\n",
        "- where can i buy snacks ?\n",
        "- I want to buy food\n",
        "\n",
        "\n",
        "## intent:toilet_enquiry\n",
        "- i neeed to pee\n",
        "- where is the rest room?\n",
        "- where is the toilet\n",
        "- is there a nearby toilet?\n",
        "- i they find toilet\n",
        "- where is the bathroom\n",
        "- i need to use the bathroom\n",
        "- where can i pee\n",
        "- i want peace\n",
        "- i am pressed\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "%store nlu_md >nlu.md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovpaAACTSSTY"
      },
      "source": [
        "Setting up our configuration for our pipeline and policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmfWtkbsuZ0i",
        "outputId": "64c7067f-0f1a-4a1a-a019-407f6db2b80c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing 'config' (str) to file 'config.yml'.\n"
          ]
        }
      ],
      "source": [
        "# Adding the NLU components to the pipeline in config.yml file\n",
        "config = \"\"\"\n",
        "language: \"en_core_web_md\"\n",
        "\n",
        "pipeline:\n",
        "- name: \"nlp_spacy\"                   # loads the spacy language model\n",
        "- name: \"tokenizer_spacy\"             # splits the sentence into tokens\n",
        "- name: \"ner_crf\"                     # uses the pretrained spacy NER model\n",
        "- name: \"intent_featurizer_spacy\"     # transform the sentence into a vector representation\n",
        "- name: \"intent_classifier_sklearn\"   # uses the vector representation to classify using SVM\n",
        "- name: \"ner_synonyms\"                # trains the synonyms\n",
        "\n",
        "policies:\n",
        "- name: \"RulePolicy\"\n",
        "  # Confidence threshold for the `core_fallback_action_name` to apply.\n",
        "  # The action will apply if no other action was predicted with\n",
        "  # a confidence >= core_fallback_threshold\n",
        "  core_fallback_threshold: 0.68\n",
        "  core_fallback_action_name: \"action_default_fallback\"\n",
        "  enable_fallback_prediction: True\n",
        "\n",
        "\n",
        "\"\"\" \n",
        "\n",
        "%store config >config.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqYxBhUyrsar"
      },
      "source": [
        "# Training the model\n",
        "Import the load_data and config modules so as to load the training data file and config file respectiely, which would be fed to the Trainer module to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6kTAyc_wjrI",
        "outputId": "40ffeb02-cddb-4da0-e60d-4cac264ce585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.2s finished\n"
          ]
        }
      ],
      "source": [
        "# Import modules for training\n",
        "from rasa_nlu.training_data import load_data\n",
        "from rasa_nlu.config import RasaNLUModelConfig\n",
        "from rasa_nlu.model import Trainer\n",
        "from rasa_nlu import config\n",
        "\n",
        "# loading the nlu training samples\n",
        "training_data = load_data(\"nlu.md\")\n",
        "trainer = Trainer(config.load(\"config.yml\"))\n",
        "\n",
        "# training the nlu\n",
        "interpreter = trainer.train(training_data)\n",
        "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2FilhqAr74r"
      },
      "source": [
        "Testing our model.\n",
        "The aim is to see how well it can predict intents, this would be then use to determind the appropriate response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McY2G4Gjwp3T",
        "outputId": "9e32e00b-1cf9-49c6-9940-5ab230366bb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"intent\": {\n",
            "    \"name\": \"choosing_item\",\n",
            "    \"confidence\": 0.2828135698895929\n",
            "  },\n",
            "  \"entities\": [],\n",
            "  \"intent_ranking\": [\n",
            "    {\n",
            "      \"name\": \"choosing_item\",\n",
            "      \"confidence\": 0.2828135698895929\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"toilet_enquiry\",\n",
            "      \"confidence\": 0.22107422237132043\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"greet\",\n",
            "      \"confidence\": 0.18720818935689895\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"restaurant_enquiry\",\n",
            "      \"confidence\": 0.11261922993313768\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"accomodation_enquiry\",\n",
            "      \"confidence\": 0.059228491850562066\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"goodbye\",\n",
            "      \"confidence\": 0.05440423941512719\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"directions\",\n",
            "      \"confidence\": 0.041882422727887614\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"thanks\",\n",
            "      \"confidence\": 0.040769634455473235\n",
            "    }\n",
            "  ],\n",
            "  \"text\": \"x\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        " # Testing the NLU model with an input message\n",
        "\n",
        "import json\n",
        "def pprint(o):   \n",
        "    print(json.dumps(o, indent=2))\n",
        "\n",
        "pprint(interpreter.parse(\"x\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGZycj1ZtBvM"
      },
      "source": [
        "This is the second part of the project where we would be dealing with stories, actions and templates so our bot can respond to queries appropriately. Stories is a path which countains intents and their respective actions to be taken.\n",
        "Actions are the the responses we want our bot to give after identifying intent.\n",
        "Templates are where we store all the actions.\n",
        "Slots are our bots memories which help it keep track of events."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXw_5ojnxLl4",
        "outputId": "afc45b4d-7106-4ad7-ffa0-aaf3893f4eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing 'stories_md' (str) to file 'stories.md'.\n"
          ]
        }
      ],
      "source": [
        "# Writing stories and saving it in the stories.md file\n",
        "\n",
        "stories_md = \"\"\"\n",
        "##  Greeting path             \n",
        "* greet              \n",
        "  - utter_greet\n",
        "\n",
        "## directions path\n",
        "* directions\n",
        "  - utter_menu\n",
        "* choosing_destination\n",
        "  - utter_destination_received\n",
        "\n",
        "## Enquires path\n",
        "* accomodation_enquiry\n",
        "  - utter_enquiry\n",
        "\n",
        "## thanks path\n",
        "* thanks\n",
        "  - utter_thanks  \n",
        "\n",
        "## restaurant path\n",
        "* restaurant_enquiry\n",
        "  - utter_restaurant_enquiry\n",
        "\n",
        "\n",
        "## toilet path\n",
        "* toilet_enquiry\n",
        "  - utter_toilet_location\n",
        "\n",
        "\n",
        "## say goodbye\n",
        "* goodbye\n",
        "  - utter_goodbye\n",
        "\n",
        "## thanks\n",
        "* thanks\n",
        "  - utter_thanks\n",
        "\n",
        "## fallback rule\n",
        "* bot_fallback\n",
        "  - action_default_fallback\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "%store stories_md >stories.md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEqlG5lCTKJn"
      },
      "source": [
        "The domain is where we link together all our files for the chatbot. The uttar_default action is he action to be taken when the confidence value of all possible intentions is below the thereshold value set inn our configuration file under the fallback policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AT7yIyMNtMe",
        "outputId": "a8134e5e-74bf-406f-8d07-574b8bfc88b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing 'domain_yml' (str) to file 'domain.yml'.\n"
          ]
        }
      ],
      "source": [
        "# Writing all the intents,slots,entities,actions and templates to domain.yml\n",
        "\n",
        "domain_yml = \"\"\"\n",
        "intents:\n",
        "- greet\n",
        "- goodbye\n",
        "- directions\n",
        "- choosing_item\n",
        "- accomodation_enquiry\n",
        "- restaurant_enquiry\n",
        "- toilet_enquiry\n",
        "- thanks\n",
        "\n",
        "\n",
        "\n",
        "slots:\n",
        "  group:\n",
        "    type: text\n",
        "\n",
        "entities:\n",
        "- group\n",
        "\n",
        "\n",
        "actions:\n",
        "- utter_greet\n",
        "- utter_menu\n",
        "- utter_destination_received\n",
        "- utter_enquiry\n",
        "- utter_toilet_location\n",
        "- utter_restaurant_enquiry\n",
        "- utter_goodbye\n",
        "- utter_thanks\n",
        "- utter_default\n",
        "\n",
        "\n",
        "templates:\n",
        "  utter_greet:\n",
        "  - text: \"\\n\\n NRC BOT: \\n\\n Hey! Welcome to RASA. How may I help you ? \\n\\n \\n\\n You:\"\n",
        "\n",
        "  utter_menu:\n",
        "  - text: \"\\n\\n NRC BOT: \\n\\n There is a bus terminal outside the station, it's just accross the road.  You can board a bus to the following destinations: \\n\\n 1. Wuse  2. Airport 3. Nyanya  4. Zuba  5. Asokoro  6. Maitama  7. Area one  8. Central area  8. Secretariat. \\n\\n Enter  the appropraite number to know when the next bus leaves the terminal. \\n\\n \\n\\n  You:\"\n",
        "\n",
        "  utter_destination_received:\n",
        "  - text: \"\\n\\n NRC BOT: \\n\\n The next bus leaves in 15 minutes, do have a safe trip. \\n\\n \\n\\n You:\"\n",
        "\n",
        "  utter_goodbye:\n",
        "  - text: \"\\n\\n NRC BOT: \\n\\n Thank you for choosing to transit with us. Waiting for your next visit. \\n\\n \\n\\n You:\"\n",
        "\n",
        "  utter_enquiry:\n",
        "  - text: \"\\n\\n NRC BOT: \\n\\n Take a right turn from the exit, there are several hotels at your service. \\n\\n \\n\\n You:\"\n",
        "\n",
        "  utter_toilet_location:\n",
        "  - text: \"\\n\\n NRC BOT: \\n\\n There is a toilet symbol on the extreme right from where you stand. \\n\\n \\n\\n You:\"\n",
        "\n",
        "  utter_restaurant_enquiry:\n",
        "  - text: \"\\n\\n NRC BOT: \\n\\n There is a food court filled with a variety of rastaurants at the extreme left after the entrance. \\n\\n \\n\\n You: \"\n",
        "\n",
        "  utter_thanks:\n",
        "  - text: \"\\n\\n NRC BOT: \\n\\n my pleasure \\n\\n \\n\\n You:\"\n",
        "\n",
        "  utter_default:\n",
        "  - text: \"\\n\\n NRC BOT: \\n\\n I'm sorry, I didn't quite understand that. Could you rephrase? \\n\\n You:\"\n",
        "\n",
        " \n",
        " \n",
        "\"\"\"\n",
        "\n",
        "%store domain_yml >domain.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ho7iCP-UVTS"
      },
      "source": [
        "Here we import our policies and the Agent module. The Agent module is used to load the file, and passed to the 'agent' model. The 'agent' model is in turn trained with the data in the stories file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IftpE7U9Nybn",
        "outputId": "a3884c2f-8de5-4bce-a1aa-2051f4c43e15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed Story Blocks: 100%|██████████| 9/9 [00:00<00:00, 303.09it/s, # trackers=1]\n",
            "Processed Story Blocks: 100%|██████████| 9/9 [00:00<00:00, 231.55it/s, # trackers=8]\n",
            "Processed Story Blocks: 100%|██████████| 9/9 [00:00<00:00, 154.16it/s, # trackers=20]\n",
            "Processed Story Blocks: 100%|██████████| 9/9 [00:00<00:00, 127.71it/s, # trackers=20]\n",
            "Processed actions: 19it [00:00, 622.89it/s, # examples=19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "masking (Masking)            (None, 5, 27)             0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                7680      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 17)                561       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 8,241\n",
            "Trainable params: 8,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "413/413 [==============================] - 1s 2ms/sample - loss: 2.7170 - acc: 0.3729\n",
            "Epoch 2/100\n",
            "413/413 [==============================] - 0s 214us/sample - loss: 2.5180 - acc: 0.5012\n",
            "Epoch 3/100\n",
            "413/413 [==============================] - 0s 254us/sample - loss: 2.2633 - acc: 0.5012\n",
            "Epoch 4/100\n",
            "413/413 [==============================] - 0s 231us/sample - loss: 2.0208 - acc: 0.5012\n",
            "Epoch 5/100\n",
            "413/413 [==============================] - 0s 222us/sample - loss: 1.9083 - acc: 0.5012\n",
            "Epoch 6/100\n",
            "413/413 [==============================] - 0s 343us/sample - loss: 1.8486 - acc: 0.5012\n",
            "Epoch 7/100\n",
            "413/413 [==============================] - 0s 240us/sample - loss: 1.8007 - acc: 0.5012\n",
            "Epoch 8/100\n",
            "413/413 [==============================] - 0s 221us/sample - loss: 1.7631 - acc: 0.5012\n",
            "Epoch 9/100\n",
            "413/413 [==============================] - 0s 240us/sample - loss: 1.7289 - acc: 0.5012\n",
            "Epoch 10/100\n",
            "413/413 [==============================] - 0s 225us/sample - loss: 1.7005 - acc: 0.5012\n",
            "Epoch 11/100\n",
            "413/413 [==============================] - 0s 227us/sample - loss: 1.6644 - acc: 0.5012\n",
            "Epoch 12/100\n",
            "413/413 [==============================] - 0s 234us/sample - loss: 1.6461 - acc: 0.5012\n",
            "Epoch 13/100\n",
            "413/413 [==============================] - 0s 220us/sample - loss: 1.6094 - acc: 0.5012\n",
            "Epoch 14/100\n",
            "413/413 [==============================] - 0s 241us/sample - loss: 1.5864 - acc: 0.5012\n",
            "Epoch 15/100\n",
            "413/413 [==============================] - 0s 257us/sample - loss: 1.5545 - acc: 0.5012\n",
            "Epoch 16/100\n",
            "413/413 [==============================] - 0s 221us/sample - loss: 1.5154 - acc: 0.5012\n",
            "Epoch 17/100\n",
            "413/413 [==============================] - 0s 225us/sample - loss: 1.4790 - acc: 0.5012\n",
            "Epoch 18/100\n",
            "413/413 [==============================] - 0s 237us/sample - loss: 1.4322 - acc: 0.5036\n",
            "Epoch 19/100\n",
            "413/413 [==============================] - 0s 229us/sample - loss: 1.3895 - acc: 0.5061\n",
            "Epoch 20/100\n",
            "413/413 [==============================] - 0s 230us/sample - loss: 1.3383 - acc: 0.5109\n",
            "Epoch 21/100\n",
            "413/413 [==============================] - 0s 228us/sample - loss: 1.2696 - acc: 0.5133\n",
            "Epoch 22/100\n",
            "413/413 [==============================] - 0s 258us/sample - loss: 1.2214 - acc: 0.5254\n",
            "Epoch 23/100\n",
            "413/413 [==============================] - 0s 226us/sample - loss: 1.1663 - acc: 0.5981\n",
            "Epoch 24/100\n",
            "413/413 [==============================] - 0s 221us/sample - loss: 1.0935 - acc: 0.6562\n",
            "Epoch 25/100\n",
            "413/413 [==============================] - 0s 268us/sample - loss: 1.0634 - acc: 0.7070\n",
            "Epoch 26/100\n",
            "413/413 [==============================] - 0s 245us/sample - loss: 1.0091 - acc: 0.7409\n",
            "Epoch 27/100\n",
            "413/413 [==============================] - 0s 221us/sample - loss: 0.9954 - acc: 0.7603\n",
            "Epoch 28/100\n",
            "413/413 [==============================] - 0s 219us/sample - loss: 0.9596 - acc: 0.7772\n",
            "Epoch 29/100\n",
            "413/413 [==============================] - 0s 228us/sample - loss: 0.9260 - acc: 0.8063\n",
            "Epoch 30/100\n",
            "413/413 [==============================] - 0s 256us/sample - loss: 0.8955 - acc: 0.8523\n",
            "Epoch 31/100\n",
            "413/413 [==============================] - 0s 226us/sample - loss: 0.8862 - acc: 0.8402\n",
            "Epoch 32/100\n",
            "413/413 [==============================] - 0s 234us/sample - loss: 0.8507 - acc: 0.8596\n",
            "Epoch 33/100\n",
            "413/413 [==============================] - 0s 226us/sample - loss: 0.8258 - acc: 0.8620\n",
            "Epoch 34/100\n",
            "413/413 [==============================] - 0s 233us/sample - loss: 0.8443 - acc: 0.8571\n",
            "Epoch 35/100\n",
            "413/413 [==============================] - 0s 268us/sample - loss: 0.7867 - acc: 0.8765\n",
            "Epoch 36/100\n",
            "413/413 [==============================] - 0s 240us/sample - loss: 0.7876 - acc: 0.8838\n",
            "Epoch 37/100\n",
            "413/413 [==============================] - 0s 234us/sample - loss: 0.7494 - acc: 0.8838\n",
            "Epoch 38/100\n",
            "413/413 [==============================] - 0s 239us/sample - loss: 0.7242 - acc: 0.9177\n",
            "Epoch 39/100\n",
            "413/413 [==============================] - 0s 229us/sample - loss: 0.7139 - acc: 0.9031\n",
            "Epoch 40/100\n",
            "413/413 [==============================] - 0s 226us/sample - loss: 0.6867 - acc: 0.9128\n",
            "Epoch 41/100\n",
            "413/413 [==============================] - 0s 241us/sample - loss: 0.6485 - acc: 0.9467\n",
            "Epoch 42/100\n",
            "413/413 [==============================] - 0s 214us/sample - loss: 0.6460 - acc: 0.9274\n",
            "Epoch 43/100\n",
            "413/413 [==============================] - 0s 235us/sample - loss: 0.6090 - acc: 0.9443\n",
            "Epoch 44/100\n",
            "413/413 [==============================] - 0s 258us/sample - loss: 0.6056 - acc: 0.9346\n",
            "Epoch 45/100\n",
            "413/413 [==============================] - 0s 253us/sample - loss: 0.5943 - acc: 0.9370\n",
            "Epoch 46/100\n",
            "413/413 [==============================] - 0s 241us/sample - loss: 0.5678 - acc: 0.9322\n",
            "Epoch 47/100\n",
            "413/413 [==============================] - 0s 261us/sample - loss: 0.5517 - acc: 0.9346\n",
            "Epoch 48/100\n",
            "413/413 [==============================] - 0s 258us/sample - loss: 0.5380 - acc: 0.9443\n",
            "Epoch 49/100\n",
            "413/413 [==============================] - 0s 211us/sample - loss: 0.5118 - acc: 0.9467\n",
            "Epoch 50/100\n",
            "413/413 [==============================] - 0s 236us/sample - loss: 0.5073 - acc: 0.9419\n",
            "Epoch 51/100\n",
            "413/413 [==============================] - 0s 240us/sample - loss: 0.5039 - acc: 0.9395\n",
            "Epoch 52/100\n",
            "413/413 [==============================] - 0s 237us/sample - loss: 0.4471 - acc: 0.9637\n",
            "Epoch 53/100\n",
            "413/413 [==============================] - 0s 222us/sample - loss: 0.4560 - acc: 0.9419\n",
            "Epoch 54/100\n",
            "413/413 [==============================] - 0s 235us/sample - loss: 0.3979 - acc: 0.9588\n",
            "Epoch 55/100\n",
            "413/413 [==============================] - 0s 242us/sample - loss: 0.4026 - acc: 0.9734\n",
            "Epoch 56/100\n",
            "413/413 [==============================] - 0s 218us/sample - loss: 0.3872 - acc: 0.9588\n",
            "Epoch 57/100\n",
            "413/413 [==============================] - 0s 232us/sample - loss: 0.3923 - acc: 0.9492\n",
            "Epoch 58/100\n",
            "413/413 [==============================] - 0s 234us/sample - loss: 0.3628 - acc: 0.9661\n",
            "Epoch 59/100\n",
            "413/413 [==============================] - 0s 239us/sample - loss: 0.3612 - acc: 0.9419\n",
            "Epoch 60/100\n",
            "413/413 [==============================] - 0s 247us/sample - loss: 0.3676 - acc: 0.9370\n",
            "Epoch 61/100\n",
            "413/413 [==============================] - 0s 246us/sample - loss: 0.3450 - acc: 0.9588\n",
            "Epoch 62/100\n",
            "413/413 [==============================] - 0s 245us/sample - loss: 0.3380 - acc: 0.9540\n",
            "Epoch 63/100\n",
            "413/413 [==============================] - 0s 234us/sample - loss: 0.3035 - acc: 0.9637\n",
            "Epoch 64/100\n",
            "413/413 [==============================] - 0s 262us/sample - loss: 0.3046 - acc: 0.9588\n",
            "Epoch 65/100\n",
            "413/413 [==============================] - 0s 241us/sample - loss: 0.2789 - acc: 0.9564\n",
            "Epoch 66/100\n",
            "413/413 [==============================] - 0s 233us/sample - loss: 0.2770 - acc: 0.9613\n",
            "Epoch 67/100\n",
            "413/413 [==============================] - 0s 254us/sample - loss: 0.2786 - acc: 0.9540\n",
            "Epoch 68/100\n",
            "413/413 [==============================] - 0s 218us/sample - loss: 0.2554 - acc: 0.9564\n",
            "Epoch 69/100\n",
            "413/413 [==============================] - 0s 232us/sample - loss: 0.2601 - acc: 0.9588\n",
            "Epoch 70/100\n",
            "413/413 [==============================] - 0s 236us/sample - loss: 0.2204 - acc: 0.9685\n",
            "Epoch 71/100\n",
            "413/413 [==============================] - 0s 250us/sample - loss: 0.2419 - acc: 0.9492\n",
            "Epoch 72/100\n",
            "413/413 [==============================] - 0s 230us/sample - loss: 0.2479 - acc: 0.9443\n",
            "Epoch 73/100\n",
            "413/413 [==============================] - 0s 234us/sample - loss: 0.2364 - acc: 0.9588\n",
            "Epoch 74/100\n",
            "413/413 [==============================] - 0s 250us/sample - loss: 0.2155 - acc: 0.9734\n",
            "Epoch 75/100\n",
            "413/413 [==============================] - 0s 232us/sample - loss: 0.2196 - acc: 0.9540\n",
            "Epoch 76/100\n",
            "413/413 [==============================] - 0s 220us/sample - loss: 0.1913 - acc: 0.9613\n",
            "Epoch 77/100\n",
            "413/413 [==============================] - 0s 225us/sample - loss: 0.1910 - acc: 0.9661\n",
            "Epoch 78/100\n",
            "413/413 [==============================] - 0s 230us/sample - loss: 0.2103 - acc: 0.9516\n",
            "Epoch 79/100\n",
            "413/413 [==============================] - 0s 234us/sample - loss: 0.1970 - acc: 0.9661\n",
            "Epoch 80/100\n",
            "413/413 [==============================] - 0s 230us/sample - loss: 0.1817 - acc: 0.9709\n",
            "Epoch 81/100\n",
            "413/413 [==============================] - 0s 255us/sample - loss: 0.1645 - acc: 0.9661\n",
            "Epoch 82/100\n",
            "413/413 [==============================] - 0s 232us/sample - loss: 0.1937 - acc: 0.9685\n",
            "Epoch 83/100\n",
            "413/413 [==============================] - 0s 237us/sample - loss: 0.1677 - acc: 0.9709\n",
            "Epoch 84/100\n",
            "413/413 [==============================] - 0s 233us/sample - loss: 0.1874 - acc: 0.9564\n",
            "Epoch 85/100\n",
            "413/413 [==============================] - 0s 236us/sample - loss: 0.1570 - acc: 0.9709\n",
            "Epoch 86/100\n",
            "413/413 [==============================] - 0s 223us/sample - loss: 0.2019 - acc: 0.9467\n",
            "Epoch 87/100\n",
            "413/413 [==============================] - 0s 250us/sample - loss: 0.1521 - acc: 0.9734\n",
            "Epoch 88/100\n",
            "413/413 [==============================] - 0s 224us/sample - loss: 0.1671 - acc: 0.9637\n",
            "Epoch 89/100\n",
            "413/413 [==============================] - 0s 256us/sample - loss: 0.1570 - acc: 0.9685\n",
            "Epoch 90/100\n",
            "413/413 [==============================] - 0s 240us/sample - loss: 0.1419 - acc: 0.9782\n",
            "Epoch 91/100\n",
            "413/413 [==============================] - 0s 231us/sample - loss: 0.1550 - acc: 0.9685\n",
            "Epoch 92/100\n",
            "413/413 [==============================] - 0s 225us/sample - loss: 0.1372 - acc: 0.9709\n",
            "Epoch 93/100\n",
            "413/413 [==============================] - 0s 280us/sample - loss: 0.1665 - acc: 0.9613\n",
            "Epoch 94/100\n",
            "413/413 [==============================] - 0s 225us/sample - loss: 0.1440 - acc: 0.9685\n",
            "Epoch 95/100\n",
            "413/413 [==============================] - 0s 222us/sample - loss: 0.1472 - acc: 0.9758\n",
            "Epoch 96/100\n",
            "413/413 [==============================] - 0s 237us/sample - loss: 0.1371 - acc: 0.9709\n",
            "Epoch 97/100\n",
            "413/413 [==============================] - 0s 266us/sample - loss: 0.1634 - acc: 0.9588\n",
            "Epoch 98/100\n",
            "413/413 [==============================] - 0s 231us/sample - loss: 0.1364 - acc: 0.9661\n",
            "Epoch 99/100\n",
            "413/413 [==============================] - 0s 231us/sample - loss: 0.1577 - acc: 0.9637\n",
            "Epoch 100/100\n",
            "413/413 [==============================] - 0s 231us/sample - loss: 0.1369 - acc: 0.9734\n"
          ]
        }
      ],
      "source": [
        "# Import the policies and agent\n",
        "from rasa_core.policies import FallbackPolicy, MemoizationPolicy,KerasPolicy\n",
        "from rasa_core.agent import Agent\n",
        "\n",
        "# Initialize the model with `domain.yml`\n",
        "agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy(), ])\n",
        "\n",
        "# loading our  training dialogues from `stories.md` \n",
        "training_data = agent.load_data('stories.md')\n",
        "\n",
        "\n",
        "# Training the model\n",
        "agent.train(\n",
        "    training_data)\n",
        "    #validation_split=0.0,\n",
        "    #epochs=200)\n",
        "\n",
        "agent.persist('models/dialogue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZP69uZMVbSL"
      },
      "source": [
        "Load the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "FelGadA5uZPh"
      },
      "outputs": [],
      "source": [
        "#Starting the Bot\n",
        "from rasa_core.agent import Agent\n",
        "agent = Agent.load('models/dialogue', interpreter=model_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxgGAybxVnG_"
      },
      "source": [
        "Write a function to tale inputs for the chatbot and gives out an output while stopping when 'stop' is typed in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1nOPTca0QBA",
        "outputId": "d3a827e1-7328-43eb-f9e9-726d46058f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your bot is ready to talk! Type your messages here or send 'stop'\n",
            "\n",
            "You:\n",
            "Good morning\n",
            "NRC BOT:\n",
            "Hey! Welcome to RASA. How may I help you ?\n",
	    "You:\n",
	    "Bye\n",
	    "NRC BOT:\n",
	    "Thank you for choosing to transit with us. Waiting for your next visit.\n",
            "You:\n",
            "stop\n"
          ]
        }
      ],
      "source": [
        "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\" + \"\\n\\n\" + \"You:\")\n",
        "while True:\n",
        "    a = input()\n",
        "    if a == 'stop':\n",
        "        break\n",
        "    responses = agent.handle_message(a)\n",
        "    for response in responses:\n",
        "        print(response[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O086vj-kuqm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NRC chatbot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
