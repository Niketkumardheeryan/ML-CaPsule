{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\akshay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\akshay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\akshay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\akshay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.5.10)\n",
      "Requirement already satisfied: tqdm in c:\\users\\akshay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\akshay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.7 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.9/1.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.1/1.7 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.2/1.7 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.2/1.7 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.2/1.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.5 MB/s eta 0:00:00\n",
      "Installing collected packages: networkx\n",
      "Successfully installed networkx-3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "%pip install networkx\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AKSHAY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AKSHAY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He continued to wait for Marta to appear with the pets, but she still was nowhere to be seen. Dave watched as the forest burned up on the hill, only a few miles from her house. Dave went through his mental list of the most important papers and documents that they couldn't leave behind. The car had been hastily packed and Marta was inside trying to round up the last of the pets. He scolded himself for not having prepared these better in advance and hoped that he had remembered everything that was needed.\n"
     ]
    }
   ],
   "source": [
    "def read_article(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    "\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    "\n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    "\n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "\n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2:\n",
    "                continue\n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "    return similarity_matrix\n",
    "\n",
    "def generate_summary(text, threshold=0.2):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    sentences = read_article(text)\n",
    "    sentence_similarity_matrix = build_similarity_matrix(sentences, stop_words)\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    # Sort the sentences by their PageRank scores\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "    # Include sentences in the summary if their score is above the threshold\n",
    "    for score, sentence in ranked_sentences:\n",
    "        if score > threshold:\n",
    "            summarize_text.append(sentence)\n",
    "\n",
    "    # Combine selected sentences to create the final summary\n",
    "    summary = ' '.join(summarize_text)\n",
    "    return summary\n",
    "\n",
    "# Example usage:\n",
    "text = \"Dave watched as the forest burned up on the hill, only a few miles from her house. The car had been hastily packed and Marta was inside trying to round up the last of the pets. Dave went through his mental list of the most important papers and documents that they couldn't leave behind. He scolded himself for not having prepared these better in advance and hoped that he had remembered everything that was needed. He continued to wait for Marta to appear with the pets, but she still was nowhere to be seen.\"\n",
    "summary = generate_summary(text)\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
