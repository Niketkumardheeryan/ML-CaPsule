{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf93818-f977-4424-854a-d2d4d1014327",
   "metadata": {},
   "source": [
    "# Importing Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc258266-787b-4828-abbd-c7d85dbcbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83265c-e452-4411-9abd-4002264a5cdd",
   "metadata": {},
   "source": [
    "# Creating Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6741c791-fd7b-4f99-85cd-e904f46bd558",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"Hindi Letter classification üïâÔ∏è\") #Title of page\n",
    "st.divider() #A divider line\n",
    "st.image(\"https://i.pinimg.com/474x/ce/79/6c/ce796ceb0d16147fd7853f1a3fdd0210.jpg\") # adds a image\n",
    "st.subheader(\"Introduction\") # adds a subheader\n",
    "st.write('''\n",
    "The web app is created using streamlit framework. It contains a heading, small introduction and then a image uploader.\n",
    "          After the user uploads image, the image goes to backend and respected class is predicted by the CNN model and then\n",
    "          the uploaded image along with prediction is showed. We can play with prediciton time and accuracy by changing batch_size,\n",
    "          number of epochs and using a different CNN architecture.\n",
    "\n",
    "''') # adds a piece of text\n",
    "st.divider()\n",
    "uploaded_file = st.file_uploader(\"Enter image to Predict\", type=['png', 'jpg']) # adds a file uploader widget\n",
    "submit = st.button(\"Submit\") #submit button\n",
    "st.write(\"It may take 2-3 minutes to predict the image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba616ee9-aaed-42dc-88c3-8b59440f9a05",
   "metadata": {},
   "source": [
    "# After clicking submit button"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce7f76b-2b9d-4e63-bf1a-9ef8037598e3",
   "metadata": {},
   "source": [
    "## Creating training data and then making training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282d9bc-167d-41a9-8e71-e27e825db2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if submit:\n",
    "    if uploaded_file is not None:\n",
    "\n",
    "        import tensorflow as tf\n",
    "        from keras.preprocessing.image import ImageDataGenerator \n",
    "        train_datagen = ImageDataGenerator(rescale = 1./255, # applying modifications to training set\n",
    "                                        shear_range = 0.2,\n",
    "                                        zoom_range = 0.2,\n",
    "                                        horizontal_flip = True)\n",
    "        training_set = train_datagen.flow_from_directory('Dataset/dataset/train', # creating trainig set of batch size 30\n",
    "                                                        target_size = (64, 64),\n",
    "                                                        batch_size = 30,\n",
    "                                                        class_mode = 'categorical')\n",
    "        test_datagen = ImageDataGenerator(rescale = 1./255) # applying modification to test set\n",
    "        test_set = test_datagen.flow_from_directory('Dataset/dataset/test', # creating test set of batch size 30\n",
    "                                                    target_size = (64, 64),\n",
    "                                                    batch_size = 30,\n",
    "                                                    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd752f66-bd25-4b58-899c-62574e039406",
   "metadata": {},
   "source": [
    "## Creating LENET-5 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168fa8c-6e8c-4a71-ad24-7b0e004581f2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # LeNet-5 architecture\n",
    "        lenet = tf.keras.models.Sequential()\n",
    "\n",
    "        # Layer 1: Convolutional layer with 6 filters, kernel size 5x5, and ReLU activation\n",
    "        lenet.add(tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='relu', input_shape=[64, 64, 3]))\n",
    "\n",
    "        # Layer 2: Average pooling layer with pool size 2x2 and strides 2\n",
    "        lenet.add(tf.keras.layers.AveragePooling2D(pool_size=2, strides=2))\n",
    "\n",
    "        # Layer 3: Convolutional layer with 16 filters, kernel size 5x5, and ReLU activation\n",
    "        lenet.add(tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu'))\n",
    "\n",
    "        # Layer 4: Average pooling layer with pool size 2x2 and strides 2\n",
    "        lenet.add(tf.keras.layers.AveragePooling2D(pool_size=2, strides=2))\n",
    "\n",
    "        # Layer 5: Flatten layer\n",
    "        lenet.add(tf.keras.layers.Flatten())\n",
    "\n",
    "        # Layer 6: Fully connected layer with 120 units and ReLU activation\n",
    "        lenet.add(tf.keras.layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "        # Layer 7: Fully connected layer with 84 units and ReLU activation\n",
    "        lenet.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "        # Layer 8: Output layer with 46 units (assuming it's the number of classes) and softmax activation\n",
    "        lenet.add(tf.keras.layers.Dense(units=46, activation='softmax'))\n",
    "\n",
    "        # Compile the model with Adam optimizer and categorical crossentropy loss\n",
    "        lenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        lenet.fit(x = training_set, validation_data = test_set, epochs = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf1547-1ee5-49ef-8fea-7894d6bef294",
   "metadata": {},
   "source": [
    "## Predicting the class of uploaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9db30-68df-4f99-a6cc-2cc8fb97a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "        from keras.preprocessing import image\n",
    "        if uploaded_file is not None: # if user has uploaded any file\n",
    "            try:\n",
    "                class_indices = training_set.class_indices\n",
    "                test_image = image.load_img(uploaded_file, target_size = (64, 64)) # modifying uploaded image to be sent for prediction\n",
    "                test_image = image.img_to_array(test_image) # converting image to array\n",
    "                test_image = np.expand_dims(test_image, axis = 0) # changing dimension of image\n",
    "                result = lenet.predict(test_image) #getting the prediction\n",
    "                prediction = lenet.predict(test_image)\n",
    "                predicted_class_index = np.argmax(prediction) # getting the classindex with highest probability\n",
    "                predicted_class_name = [key for key, value in class_indices.items() if value == predicted_class_index][0] #getting the name corresponding to predicted index\n",
    "                st.image(uploaded_file) # displaying uploaded image\n",
    "                st.write(predicted_class_name) # writing the prediction in web app\n",
    "                print(predicted_class_index)\n",
    "            except:\n",
    "                st.write(\"There is error in file provided\")\n",
    "                \n",
    "                \n",
    "        elif uploaded_file is None: # if no file uploaded and submit is clicked, this error comes up\n",
    "            st.markdown(\":red[Please enter a image]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
