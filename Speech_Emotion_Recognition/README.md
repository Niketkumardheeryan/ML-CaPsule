# Speech Emotion Recognition

## Short description of package/script

- Through all the available senses humans can actually sense the emotional state of their communication partner. 
- The emotional detection is natural for humans but it is very difficult task for computers; although they can easily understand content based information, accessing the depth behind content is difficult and thatâ€™s what speech emotion recognition (SER) sets out to do. 
- It is a system through which various audio speech files are classified into different emotions such as happy, sad, anger and neutral by computer. 
- SER can be used in areas such as the medical field or customer call centers. With this project I hope to look into applying this model into an app that individuals with ASD can use when speaking to others to help guide conversation and create/maintain healthy relationships with others who have deficits in understanding others emotions.

## Dataset used

The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) Dataset from Kaggle contains 1440 audio files from 24 Actors vocalizing two lexically-matched statements. Emotions include angry, happy, sad, fearful, calm, neutral, disgust, and surprised.

## Output

| Model Accuracy | Confusion Matrix |
| ------ | ------- |
|![Initial_Model_Accuracy](https://user-images.githubusercontent.com/58680590/123913576-ffd15800-d99b-11eb-87a1-7afee15cbde1.png) | ![Initial_Model_Confusion_Matrix](https://user-images.githubusercontent.com/58680590/123913602-0790fc80-d99c-11eb-9c02-e6f85b839f43.png) |


## Author(s)

[Omkar Kolte](https://github.com/psyduck1203)
