{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the Libraries**"
      ],
      "metadata": {
        "id": "KkuYOH76AvQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "E4hRRMZ-tZUB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Loading the Dataset**"
      ],
      "metadata": {
        "id": "G6Oc268OA2ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('/content/airline-passengers - Sheet1.csv')"
      ],
      "metadata": {
        "id": "6dUHPrbVvSR9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Data Preprocessing**"
      ],
      "metadata": {
        "id": "OxLBg4Y3A8P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to a numpy array\n",
        "data_array = data['Passengers'].values\n",
        "\n",
        "# Normalize the data\n",
        "data_array = data_array / 1000.0"
      ],
      "metadata": {
        "id": "DVsfQO6zvWID"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_size = int(0.8 * len(data_array))\n",
        "train_data, test_data = data_array[0:train_size], data_array[train_size:len(data_array)]"
      ],
      "metadata": {
        "id": "vNLhlJ32vc7G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to create sequences from the data\n",
        "def create_sequences(data, seq_len):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        sequences.append(data[i:i+seq_len])\n",
        "    return np.array(sequences)"
      ],
      "metadata": {
        "id": "8F7Wc3QRvfa0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences from the training and testing data\n",
        "seq_len = 12\n",
        "train_sequences = create_sequences(train_data, seq_len)\n",
        "test_sequences = create_sequences(test_data, seq_len)"
      ],
      "metadata": {
        "id": "RDHkb_YIvh1p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom dataset class for our sequences\n",
        "class SequenceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.sequences[idx]\n",
        "        x = sequence[:-1]\n",
        "        y = sequence[-1]\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "ol_Mqo90vko5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders for the training and testing data\n",
        "batch_size = 32\n",
        "train_dataset = SequenceDataset(train_sequences)\n",
        "test_dataset = SequenceDataset(test_sequences)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Zj-B19QVvoxb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Create the LSTM Model**"
      ],
      "metadata": {
        "id": "TOcSg4ShBKAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(1, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "TJ5wJr2-vtfA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "model = LSTMModel(input_dim=1, hidden_dim=50, output_dim=1)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "n7EY3jZBvy75"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Train The Model**"
      ],
      "metadata": {
        "id": "ZHCr44ytBPu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(100):\n",
        "    for x, y in train_loader:\n",
        "        x = x.unsqueeze(2)\n",
        "        y = y.unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV5DS6dnw9gU",
        "outputId": "a61d3986-00ec-4a95-f828-ef19e66becae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.005805084947496653\n",
            "Epoch 2, Loss: 0.003412355203181505\n",
            "Epoch 3, Loss: 0.0060778516344726086\n",
            "Epoch 4, Loss: 0.0014699731254950166\n",
            "Epoch 5, Loss: 0.007481544278562069\n",
            "Epoch 6, Loss: 0.0018805249128490686\n",
            "Epoch 7, Loss: 0.006202310789376497\n",
            "Epoch 8, Loss: 0.0032763034105300903\n",
            "Epoch 9, Loss: 0.006707929074764252\n",
            "Epoch 10, Loss: 0.0026396499015390873\n",
            "Epoch 11, Loss: 0.0016445403452962637\n",
            "Epoch 12, Loss: 0.003928287886083126\n",
            "Epoch 13, Loss: 0.006303322501480579\n",
            "Epoch 14, Loss: 0.0011638139840215445\n",
            "Epoch 15, Loss: 0.002622112398967147\n",
            "Epoch 16, Loss: 0.0024443145375698805\n",
            "Epoch 17, Loss: 0.0037794082891196012\n",
            "Epoch 18, Loss: 0.002289674011990428\n",
            "Epoch 19, Loss: 0.004236054141074419\n",
            "Epoch 20, Loss: 0.001733946381136775\n",
            "Epoch 21, Loss: 0.003110318211838603\n",
            "Epoch 22, Loss: 0.0025738514959812164\n",
            "Epoch 23, Loss: 0.002754020970314741\n",
            "Epoch 24, Loss: 0.005498877260833979\n",
            "Epoch 25, Loss: 0.0021865335293114185\n",
            "Epoch 26, Loss: 0.0028568808920681477\n",
            "Epoch 27, Loss: 0.0025150238070636988\n",
            "Epoch 28, Loss: 0.0025290190242230892\n",
            "Epoch 29, Loss: 0.002088583307340741\n",
            "Epoch 30, Loss: 0.001548347412608564\n",
            "Epoch 31, Loss: 0.0006224023527465761\n",
            "Epoch 32, Loss: 0.0015939513687044382\n",
            "Epoch 33, Loss: 0.00180751399602741\n",
            "Epoch 34, Loss: 0.0008785305544734001\n",
            "Epoch 35, Loss: 0.0009475042461417615\n",
            "Epoch 36, Loss: 0.0016921877395361662\n",
            "Epoch 37, Loss: 0.0017218071734532714\n",
            "Epoch 38, Loss: 0.0034489876125007868\n",
            "Epoch 39, Loss: 0.001483479281887412\n",
            "Epoch 40, Loss: 0.0013203684939071536\n",
            "Epoch 41, Loss: 0.0010557279456406832\n",
            "Epoch 42, Loss: 0.001155300997197628\n",
            "Epoch 43, Loss: 0.0014191981172189116\n",
            "Epoch 44, Loss: 0.003154115052893758\n",
            "Epoch 45, Loss: 0.001626004814170301\n",
            "Epoch 46, Loss: 0.0018242917722091079\n",
            "Epoch 47, Loss: 0.0011243775952607393\n",
            "Epoch 48, Loss: 0.0008295791922137141\n",
            "Epoch 49, Loss: 0.0011694898130372167\n",
            "Epoch 50, Loss: 0.00044137114309705794\n",
            "Epoch 51, Loss: 0.0006254432373680174\n",
            "Epoch 52, Loss: 0.001351109123788774\n",
            "Epoch 53, Loss: 0.0007096435874700546\n",
            "Epoch 54, Loss: 0.002187434583902359\n",
            "Epoch 55, Loss: 0.0005320738418959081\n",
            "Epoch 56, Loss: 0.0010979025391861796\n",
            "Epoch 57, Loss: 0.0014025616692379117\n",
            "Epoch 58, Loss: 0.0015168115496635437\n",
            "Epoch 59, Loss: 0.0017433810280635953\n",
            "Epoch 60, Loss: 0.0011857064673677087\n",
            "Epoch 61, Loss: 0.0010868770768865943\n",
            "Epoch 62, Loss: 0.0012654910096898675\n",
            "Epoch 63, Loss: 0.0006650912691839039\n",
            "Epoch 64, Loss: 0.0013869337271898985\n",
            "Epoch 65, Loss: 0.0006910403026267886\n",
            "Epoch 66, Loss: 0.0013608253793790936\n",
            "Epoch 67, Loss: 0.00168359256349504\n",
            "Epoch 68, Loss: 0.0017587749753147364\n",
            "Epoch 69, Loss: 0.0012695377226918936\n",
            "Epoch 70, Loss: 0.0014421669766306877\n",
            "Epoch 71, Loss: 0.002154384972527623\n",
            "Epoch 72, Loss: 0.0014661586610600352\n",
            "Epoch 73, Loss: 0.0001411266712239012\n",
            "Epoch 74, Loss: 0.0020884710829705\n",
            "Epoch 75, Loss: 0.000544834416359663\n",
            "Epoch 76, Loss: 0.0010737698758020997\n",
            "Epoch 77, Loss: 0.0006965221837162971\n",
            "Epoch 78, Loss: 0.0008707476081326604\n",
            "Epoch 79, Loss: 0.000876876525580883\n",
            "Epoch 80, Loss: 0.0019705367740243673\n",
            "Epoch 81, Loss: 0.0009265305707231164\n",
            "Epoch 82, Loss: 0.0012891491642221808\n",
            "Epoch 83, Loss: 0.001615796354599297\n",
            "Epoch 84, Loss: 0.0011757815955206752\n",
            "Epoch 85, Loss: 0.0008261652546934783\n",
            "Epoch 86, Loss: 0.0007122147944755852\n",
            "Epoch 87, Loss: 0.0012754180934280157\n",
            "Epoch 88, Loss: 0.0010420709149912\n",
            "Epoch 89, Loss: 0.00039333736640401185\n",
            "Epoch 90, Loss: 0.0014561930438503623\n",
            "Epoch 91, Loss: 0.0019125246908515692\n",
            "Epoch 92, Loss: 0.0022644251585006714\n",
            "Epoch 93, Loss: 0.002291489625349641\n",
            "Epoch 94, Loss: 0.0011742636561393738\n",
            "Epoch 95, Loss: 0.0012686420232057571\n",
            "Epoch 96, Loss: 0.0025368931237608194\n",
            "Epoch 97, Loss: 0.0012529157102108002\n",
            "Epoch 98, Loss: 0.0011661649914458394\n",
            "Epoch 99, Loss: 0.0009032532689161599\n",
            "Epoch 100, Loss: 0.0009197881445288658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Evaluating Model**"
      ],
      "metadata": {
        "id": "eMa6a8eyBU8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x = x.unsqueeze(2)\n",
        "        y = y.unsqueeze(1)\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        test_loss += loss.item()\n",
        "test_loss /= len(test_loader)\n",
        "print(f'Test Loss: {test_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um7UY6Hjw_Od",
        "outputId": "4cfa3cf7-df46-4aaf-d4b9-2122d64a33f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.003033713437616825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model to predict the next sequence of numbers\n",
        "def predict_next_sequence(model, sequence, seq_len):\n",
        "    predicted_sequence = []\n",
        "    current_sequence = torch.tensor(sequence[-seq_len:], dtype=torch.float32).unsqueeze(0).unsqueeze(2)\n",
        "\n",
        "    for i in range(12):\n",
        "        with torch.no_grad():\n",
        "            output = model(current_sequence)\n",
        "            predicted_value = output.item()\n",
        "            predicted_sequence.append(predicted_value)\n",
        "\n",
        "            # Update the current sequence to include the predicted value\n",
        "            current_sequence = torch.cat([current_sequence[:, 1:, :], torch.tensor([[[predicted_value]]], dtype=torch.float32)], dim=1)\n",
        "\n",
        "    return predicted_sequence"
      ],
      "metadata": {
        "id": "YJn3G4rFxEVC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Final Result**"
      ],
      "metadata": {
        "id": "qgDwSnTBBebr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted sequence\n",
        "predicted_sequence = predict_next_sequence(model, data_array, seq_len)\n",
        "\n",
        "print('Predicted Next Sequence:', predicted_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siLZvno6xfb3",
        "outputId": "7b3257cf-0e00-4ec0-b611-e363f7112c2f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Next Sequence: [0.3849259614944458, 0.3904801607131958, 0.39612001180648804, 0.3974493741989136, 0.39933568239212036, 0.3995046615600586, 0.3980133533477783, 0.394961953163147, 0.39221280813217163, 0.3911033272743225, 0.3923373222351074, 0.39604806900024414]\n"
          ]
        }
      ]
    }
  ]
}